{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import msoffcrypto\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Configurar \n",
    "pl.set_random_seed(42)\n",
    "\n",
    "# CONFIGURACIÓ\n",
    "ruta_excel = r'ruta/del/arxiu.xlsx'\n",
    "tu_contraseña = '*****'\n",
    "\n",
    "# Desxifrar arxiu\n",
    "decrypted_workbook = io.BytesIO()\n",
    "with open(ruta_excel, 'rb') as file:\n",
    "    office_file = msoffcrypto.OfficeFile(file)\n",
    "    office_file.load_key(password=tu_contraseña)\n",
    "    office_file.decrypt(decrypted_workbook)\n",
    "\n",
    "# Obtindre noms dels fulls\n",
    "decrypted_workbook.seek(0)\n",
    "wb = load_workbook(decrypted_workbook, read_only=True)\n",
    "nombres_hojas = wb.sheetnames\n",
    "print(\"Fulls trobats:\")\n",
    "for i, nombre in enumerate(nombres_hojas):\n",
    "    print(f\"{i + 1}: {nombre}\")\n",
    "\n",
    "# Llegir només el full número 5\n",
    "indice_hoja = 5  # Full 5 \n",
    "nombre_hoja5 = nombres_hojas[indice_hoja]\n",
    "\n",
    "decrypted_workbook.seek(0)\n",
    "df_hoja5 = pd.read_excel(decrypted_workbook, sheet_name=nombre_hoja5, engine='openpyxl')\n",
    "df = df_hoja5\n",
    "\n",
    "# Mostrar primeres files del full 5\n",
    "print(f\"\\nPrimeres files del full 5: {nombre_hoja5}\")\n",
    "print(df_hoja5.head())\n",
    "\n",
    "# Preparar el DataFrame\n",
    "if isinstance(df, pl.DataFrame):\n",
    "    df_pl = df\n",
    "else:\n",
    "    df_pl = pl.from_pandas(df)\n",
    "\n",
    "print(f\"Dataset original: {df_pl.shape}\")\n",
    "\n",
    "# Definir estratègia de fusió per a cada variable \n",
    "def crear_columna_fusionada(df, columnas_candidatas, nombre_resultado):\n",
    "    \"\"\"Crea una columna fusionada prenent el primer valor no-null de les candidates - DETERMINISTA\"\"\"\n",
    "    columnas_existentes = [col for col in columnas_candidatas if col in df.columns]\n",
    "\n",
    "    if not columnas_existentes:\n",
    "        return df.with_columns(pl.lit(None).alias(nombre_resultado))\n",
    "\n",
    "    # Ordenar columnes alfabèticament \n",
    "    columnas_existentes = sorted(columnas_existentes)\n",
    "    \n",
    "    # Utilitzar coalesce per a prendre el primer valor no-null\n",
    "    expresion = pl.coalesce([pl.col(col) for col in columnas_existentes])\n",
    "    return df.with_columns(expresion.alias(nombre_resultado))\n",
    "\n",
    "# Fusionar totes les variables duplicades\n",
    "print(\"\\nFUSIONANT VARIABLES DUPLICADES:\")\n",
    "\n",
    "# Fusionar Albúmina\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_pl,\n",
    "    ['ALBÚMINA', 'resultadoALBÚMINA'],\n",
    "    'ALBUMINA_FUSIONADA'\n",
    ")\n",
    "\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['fechaResultado_ALBUMINA', 'fechaResultadoALBÚMINA'],\n",
    "    'FECHA_ALBUMINA_FUSIONADA'\n",
    ")\n",
    "\n",
    "# Fusionar PCR\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['PCR', 'resultadoPCR'],\n",
    "    'PCR_FUSIONADA'\n",
    ")\n",
    "\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['fechaResultadoPCR', 'fechaResultadoPCR1'],\n",
    "    'FECHA_PCR_FUSIONADA'\n",
    ")\n",
    "\n",
    "# Fusionar Creatinina\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['resultadoCREATININA', 'resultadoCREATININA1'],\n",
    "    'CREATININA_FUSIONADA'\n",
    ")\n",
    "\n",
    "# Per a creatinina només hi ha una data\n",
    "df_fusionado = df_fusionado.with_columns(\n",
    "    pl.col('fechaResultadoCREATININA').alias('FECHA_CREATININA_FUSIONADA')\n",
    ")\n",
    "\n",
    "# Fusionar dades demogràfiques duplicades\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['descTipoPaciente', 'descTipoPaciente1'],\n",
    "    'TIPO_PACIENTE_FUSIONADO'\n",
    ")\n",
    "\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['descLinea', 'descLinea1'],\n",
    "    'LINEA_FUSIONADA'\n",
    ")\n",
    "\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['descEsquema', 'descEsquema1'],\n",
    "    'ESQUEMA_FUSIONADO'\n",
    ")\n",
    "\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['codigoPostal', 'codigoPostal1'],\n",
    "    'CODIGO_POSTAL_FUSIONADO'\n",
    ")\n",
    "\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['descHospitalCrc', 'descHospitalCrc1'],\n",
    "    'HOSPITAL_FUSIONADO'\n",
    ")\n",
    "\n",
    "df_fusionado = crear_columna_fusionada(\n",
    "    df_fusionado,\n",
    "    ['descZona', 'descZona1'],\n",
    "    'ZONA_FUSIONADA'\n",
    ")\n",
    "\n",
    "# Verificar quantas dades recuperem\n",
    "print(\"DADES RECUPERADES:\")\n",
    "print(f\"Albúmina fusionada: {df_fusionado['ALBUMINA_FUSIONADA'].drop_nulls().len():,} valors\")\n",
    "print(f\"PCR fusionada: {df_fusionado['PCR_FUSIONADA'].drop_nulls().len():,} valors\")\n",
    "print(f\"Creatinina fusionada: {df_fusionado['CREATININA_FUSIONADA'].drop_nulls().len():,} valors\")\n",
    "print(f\"Data Albúmina fusionada: {df_fusionado['FECHA_ALBUMINA_FUSIONADA'].drop_nulls().len():,} valors\")\n",
    "print(f\"Data PCR fusionada: {df_fusionado['FECHA_PCR_FUSIONADA'].drop_nulls().len():,} valors\")\n",
    "\n",
    "# Crear el mapatge per a la transformació\n",
    "variables_fusionadas = {\n",
    "    'Rockwood': {'valor': 'Rockwood', 'fecha': 'F_Rockwood'},\n",
    "    'ALBUMINA': {'valor': 'ALBUMINA_FUSIONADA', 'fecha': 'FECHA_ALBUMINA_FUSIONADA'},\n",
    "    'PCR': {'valor': 'PCR_FUSIONADA', 'fecha': 'FECHA_PCR_FUSIONADA'},\n",
    "    'CREATININA': {'valor': 'CREATININA_FUSIONADA', 'fecha': 'FECHA_CREATININA_FUSIONADA'},\n",
    "    'EUROQOL': {'valor': 'descResultadoEscala1', 'fecha': 'fechaEUROQOL'}\n",
    "}\n",
    "\n",
    "# Columnes demogràfiques fusionades\n",
    "cols_demograficas = ['SIPCOD', 'sexo', 'fecha Naci', 'fecha Exitus',\n",
    "                     'TIPO_PACIENTE_FUSIONADO', 'LINEA_FUSIONADA', 'ESQUEMA_FUSIONADO',\n",
    "                     'CODIGO_POSTAL_FUSIONADO', 'HOSPITAL_FUSIONADO', 'ZONA_FUSIONADA']\n",
    "\n",
    "print(f\"\\nPREPARATS PER A TRANSFORMAR AMB TOTES LES VARIANTS FUSIONADES\")\n",
    "print(f\"Variables a processar: {list(variables_fusionadas.keys())}\")\n",
    "\n",
    "# Transformació a format llarg amb dades fusionades\n",
    "print(\"\\nTRANSFORMANT A FORMAT LLARG:\")\n",
    "\n",
    "dfs_lista = []\n",
    "\n",
    "# Processar variables simples (no EuroQol)\n",
    "variables_ordenadas = sorted([var for var in variables_fusionadas.keys() if var != 'EUROQOL'])\n",
    "\n",
    "for variable in variables_ordenadas:\n",
    "    config = variables_fusionadas[variable]\n",
    "    col_valor = config['valor']\n",
    "    col_fecha = config['fecha']\n",
    "\n",
    "    print(f\"Processant {variable}...\")\n",
    "\n",
    "    # Filtrar només registres amb dades vàlides\n",
    "    df_temp = df_fusionado.filter(\n",
    "        (pl.col(col_valor).is_not_null()) &\n",
    "        (pl.col(col_fecha).is_not_null())\n",
    "    ).select([\n",
    "        pl.col('SIPCOD').cast(pl.Utf8),\n",
    "        pl.col(col_fecha).cast(pl.Utf8).alias('Fecha'),\n",
    "        pl.col(col_valor).cast(pl.Utf8).alias('Valor'),\n",
    "        *[pl.col(col).cast(pl.Utf8) for col in sorted(cols_demograficas[1:])]  # ORDE DETERMINISTA\n",
    "    ]).with_columns(\n",
    "        pl.lit(variable).alias('Variable')\n",
    "    )\n",
    "\n",
    "    df_temp = df_temp.sort(['SIPCOD', 'Fecha', 'Variable'])\n",
    "    \n",
    "    dfs_lista.append(df_temp)\n",
    "    print(f\"  {variable}: {len(df_temp):,} registres vàlids\")\n",
    "\n",
    "# Unir variables simples\n",
    "if dfs_lista:\n",
    "    df_simple_fusionado = pl.concat(dfs_lista, how=\"vertical\")\n",
    "    df_simple_fusionado = df_simple_fusionado.sort(['SIPCOD', 'Fecha', 'Variable'])\n",
    "    print(f\"\\nVariables simples unides: {len(df_simple_fusionado):,} files\")\n",
    "else:\n",
    "    df_simple_fusionado = pl.DataFrame()\n",
    "\n",
    "# Processar EuroQol\n",
    "print(\"\\nProcessant EuroQol...\")\n",
    "euroqol_config = variables_fusionadas['EUROQOL']\n",
    "\n",
    "euroqol_df = df_fusionado.filter(\n",
    "    (pl.col(euroqol_config['valor']).is_not_null()) &\n",
    "    (pl.col(euroqol_config['fecha']).is_not_null())\n",
    ").select([\n",
    "    pl.col('SIPCOD').cast(pl.Utf8),\n",
    "    pl.col(euroqol_config['fecha']).cast(pl.Utf8).alias('Fecha'),\n",
    "    pl.col(euroqol_config['valor']).cast(pl.Utf8).alias('Valor_Original'),\n",
    "    *[pl.col(col).cast(pl.Utf8) for col in sorted(cols_demograficas[1:])] \n",
    "])\n",
    "\n",
    "euroqol_df = euroqol_df.sort(['SIPCOD', 'Fecha'])\n",
    "\n",
    "print(f\"Dataset EuroQol: {len(euroqol_df):,} files\")\n",
    "\n",
    "# Expandir EuroQol \n",
    "if len(euroqol_df) > 0:\n",
    "    euroqol_expandido = euroqol_df.with_columns([\n",
    "        pl.col('Valor_Original').str.strip_chars().str.split('/').list.first().alias('valor_limpio')\n",
    "    ]).filter(\n",
    "        pl.col('valor_limpio').is_not_null() &\n",
    "        (pl.col('valor_limpio').str.len_chars() == 5)\n",
    "    ).with_columns([\n",
    "        pl.col('valor_limpio').str.slice(0, 1).alias('EQ5D_Movilidad'),\n",
    "        pl.col('valor_limpio').str.slice(1, 1).alias('EQ5D_CuidadoPersonal'),\n",
    "        pl.col('valor_limpio').str.slice(2, 1).alias('EQ5D_ActividadesHabituales'),\n",
    "        pl.col('valor_limpio').str.slice(3, 1).alias('EQ5D_DolorMalestar'),\n",
    "        pl.col('valor_limpio').str.slice(4, 1).alias('EQ5D_AnsiedadDepresion')\n",
    "    ])\n",
    "\n",
    "    dimensiones_eq5d = sorted(['EQ5D_Movilidad', 'EQ5D_CuidadoPersonal', 'EQ5D_ActividadesHabituales',\n",
    "                              'EQ5D_DolorMalestar', 'EQ5D_AnsiedadDepresion'])\n",
    "\n",
    "    euroqol_expandido = euroqol_expandido.sort(['SIPCOD', 'Fecha'])\n",
    "\n",
    "    euroqol_largo = euroqol_expandido.unpivot(\n",
    "        index=['SIPCOD', 'Fecha'] + sorted(cols_demograficas[1:]), \n",
    "        on=dimensiones_eq5d,\n",
    "        variable_name='Variable',\n",
    "        value_name='Valor'\n",
    "    )\n",
    "    \n",
    "    euroqol_largo = euroqol_largo.sort(['SIPCOD', 'Fecha', 'Variable'])\n",
    "    \n",
    "    print(f\"  EuroQol expandit: {len(euroqol_largo):,} files\")\n",
    "else:\n",
    "    euroqol_largo = pl.DataFrame()\n",
    "\n",
    "# Unir tot\n",
    "dataframes_finales = []\n",
    "if len(df_simple_fusionado) > 0:\n",
    "    dataframes_finales.append(df_simple_fusionado)\n",
    "    print(f\"\\nVariables simples: {len(df_simple_fusionado):,} files\")\n",
    "\n",
    "if len(euroqol_largo) > 0:\n",
    "    dataframes_finales.append(euroqol_largo)\n",
    "    print(f\"EuroQol: {len(euroqol_largo):,} files\")\n",
    "\n",
    "if dataframes_finales:\n",
    "    columnas_comunes = None\n",
    "    for df in dataframes_finales:\n",
    "        if columnas_comunes is None:\n",
    "            columnas_comunes = sorted(df.columns)\n",
    "        else:\n",
    "            columnas_comunes = sorted([col for col in columnas_comunes if col in df.columns])\n",
    "\n",
    "    print(f\"Columnes comunes: {len(columnas_comunes)}\")\n",
    "\n",
    "    # Reordenar columnes\n",
    "    dataframes_reordenados = [df.select(columnas_comunes) for df in dataframes_finales]\n",
    "    df_final_mejorado = pl.concat(dataframes_reordenados, how=\"vertical\")\n",
    "\n",
    "    print(f\"\\nRESULTAT MILLORAT: {len(df_final_mejorado):,} files totals\")\n",
    "    print(f\"Pacients únics: {df_final_mejorado['SIPCOD'].n_unique():,}\")\n",
    "\n",
    "    df_final_mejorado = df_final_mejorado.sort(['SIPCOD', 'Fecha', 'Variable', 'Valor'])\n",
    "\n",
    "    # Completar dades demogràfiques\n",
    "    cols_rellenar = sorted([col for col in cols_demograficas[1:] if col in df_final_mejorado.columns])\n",
    "    if cols_rellenar:\n",
    "        df_final_mejorado = df_final_mejorado.with_columns([\n",
    "            pl.col(col).fill_null(strategy=\"forward\").fill_null(strategy=\"backward\").over('SIPCOD')\n",
    "            for col in cols_rellenar\n",
    "        ])\n",
    "\n",
    "    # Eliminar duplicats \n",
    "    \n",
    "    df_final_mejorado = df_final_mejorado.sort(['SIPCOD', 'Fecha', 'Variable', 'Valor'])\n",
    "    df_final_mejorado = df_final_mejorado.unique(maintain_order=True)\n",
    "\n",
    "    print(f\"RESULTAT FINAL: {df_final_mejorado.shape}\")\n",
    "\n",
    "    # Mostrar distribució per variable\n",
    "    print(f\"\\nDISTRIBUCIÓ PER VARIABLE:\")\n",
    "    conteo_final = df_final_mejorado.group_by('Variable').agg(pl.len().alias('count')).sort(['Variable'])  # ORDE ALFABÈTIC\n",
    "    print(conteo_final)\n",
    "\n",
    "  \n",
    "    print(f\"Abans: ~33,805 files\")\n",
    "    print(f\"Ara: {len(df_final_mejorado):,} files\")\n",
    "    if len(df_final_mejorado) > 0:\n",
    "        mejora = len(df_final_mejorado) - 33805\n",
    "        porcentaje = ((len(df_final_mejorado) / 33805) - 1) * 100\n",
    "        print(f\"Increment: +{mejora:,} files ({porcentaje:.1f}% més dades!)\")\n",
    "\n",
    "else:\n",
    "    print(\"No s'han pogut processar les dades\")\n",
    "    df_final_mejorado = pl.DataFrame()\n",
    "\n",
    "# Assignar el resultat final al DataFrame principal\n",
    "df = df_final_mejorado\n",
    "\n",
    "# Classificació correcta de variables\n",
    "variables_euroqol = df.filter(pl.col(\"Variable\").str.starts_with(\"EQ5D\"))[\"Variable\"].unique().sort()\n",
    "variables_numericas = sorted([\"ALBUMINA\", \"PCR\", \"CREATININA\", \"Rockwood\"]) \n",
    "variables_ordinales = variables_euroqol.to_list()\n",
    "\n",
    "# Neteja amb càlculs temporals clau\n",
    "df_clean = df.with_columns([\n",
    "    # Conversió de dades\n",
    "    pl.col(\"Fecha\").str.to_datetime(strict=False),\n",
    "    pl.col(\"fecha Naci\").str.to_datetime(strict=False),\n",
    "    pl.col(\"fecha Exitus\").str.to_datetime(strict=False),\n",
    "\n",
    "    # Valors segons tipus de variable\n",
    "    pl.when(pl.col(\"Variable\").is_in(variables_numericas))\n",
    "      .then(pl.col(\"Valor\").cast(pl.Float64, strict=False))\n",
    "      .otherwise(None).alias(\"valor_numerico\"),\n",
    "\n",
    "    pl.when(pl.col(\"Variable\").is_in(variables_ordinales))\n",
    "      .then(pl.col(\"Valor\").cast(pl.Int32, strict=False))\n",
    "      .otherwise(None).alias(\"valor_ordinal\")\n",
    "]).with_columns([\n",
    "    # Edat al moment de la mesura\n",
    "    ((pl.col(\"Fecha\") - pl.col(\"fecha Naci\")).dt.total_days()).alias(\"edad_dias_medicion\"),\n",
    "\n",
    "    # Estat vital\n",
    "    pl.col(\"fecha Exitus\").is_not_null().alias(\"fallecido\"),\n",
    "\n",
    "    # Temps fins a la defunció  o fins a l'última mesura (si viu)\n",
    "    pl.when(pl.col(\"fecha Exitus\").is_not_null())\n",
    "      .then((pl.col(\"fecha Exitus\") - pl.col(\"Fecha\")).dt.total_days())\n",
    "      .otherwise(None).alias(\"dias_hasta_exitus\"),\n",
    "\n",
    "    # Temps de supervivència des de la mesura fins a l'esdeveniment o censura\n",
    "    pl.when(pl.col(\"fecha Exitus\").is_not_null())\n",
    "      .then((pl.col(\"fecha Exitus\") - pl.col(\"Fecha\")).dt.total_days())\n",
    "      .otherwise((pl.lit(\"2025-06-27\").str.to_date() - pl.col(\"Fecha\").dt.date()).dt.total_days())\n",
    "      .alias(\"tiempo_supervivencia\")\n",
    "])\n",
    "\n",
    "# ORDENAMENT \n",
    "df_clean = df_clean.sort(['SIPCOD', 'Fecha', 'Variable', 'Valor'])\n",
    "\n",
    "print(\"\\nDATASET NET I\")\n",
    "print(f\"Forma final: {df_clean.shape}\")\n",
    "print(f\"Columnes disponibles: {sorted(df_clean.columns)}\") \n",
    "print(f\"Variables numèriques: {variables_numericas}\")\n",
    "print(f\"Variables ordinals EuroQol: {sorted(variables_ordinales)}\")  \n",
    "\n",
    "import hashlib\n",
    "def crear_hash_verificacion(df):\n",
    "    \"\"\"Crea un hash del DataFrame per verificar la reproducibilitat\"\"\"\n",
    "    df_sorted = df.sort(sorted(df.columns))\n",
    "    data_string = str(df_sorted.to_pandas().to_string())\n",
    "    hash_resultado = hashlib.md5(data_string.encode()).hexdigest()\n",
    "    print(f\"Hash de verificació: {hash_resultado}\")\n",
    "    return hash_resultado\n",
    "\n",
    "hash_final = crear_hash_verificacion(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfddcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llistat de tipus de pacient a conservar\n",
    "tipos_a_mantener = [\n",
    "    \"Crónico pluripatológico\",\n",
    "\"Paliativo no oncológico\",\n",
    "\"Paliativo oncológico\"\n",
    "]\n",
    "\n",
    "# Aplicar el filtre en polars\n",
    "df_filtrado_polars = df_clean.filter(\n",
    "    pl.col(\"TIPO_PACIENTE_FUSIONADO\").is_in(tipos_a_mantener)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df_filtrado_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "#from jinja2 import Template\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuració d'estil\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANÀLISI DE SUPERVIVÈNCIA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# PREPARACIÓ DE DADES\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n1. PREPARACIÓ DE DADES\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Convertir df_clean a format adequat\n",
    "if hasattr(df_clean, 'to_pandas'):\n",
    "    df_surv = df_clean.to_pandas()\n",
    "else:\n",
    "    df_surv = df_clean.copy()\n",
    "\n",
    "print(f\"Dataset original: {df_surv.shape}\")\n",
    "\n",
    "# Crear dataset per pacient\n",
    "df_pacients = df_surv.groupby('SIPCOD').agg({\n",
    "    'edad_dias_medicion': 'first',\n",
    "    'fallecido': 'first', \n",
    "    'tiempo_supervivencia': 'first',\n",
    "    'sexo': 'first',\n",
    "    'TIPO_PACIENTE_FUSIONADO': 'first',\n",
    "    'HOSPITAL_FUSIONADO': 'first',\n",
    "    'ZONA_FUSIONADA': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Convertir variables temporals\n",
    "df_pacients['edad_años'] = df_pacients['edad_dias_medicion'] / 365.25\n",
    "df_pacients['tiempo_meses'] = df_pacients['tiempo_supervivencia'] / 30.44\n",
    "df_pacients['evento'] = df_pacients['fallecido'].astype(int)\n",
    "\n",
    "print(f\"Pacients únics: {len(df_pacients)}\")\n",
    "\n",
    "# Afegir variables clíniques -> valor basal (primera mesura disponible)\n",
    "variables_cliniques = {\n",
    "    'Rockwood': 'rockwood_basal',\n",
    "    'ALBUMINA': 'albumina_basal', \n",
    "    'PCR': 'pcr_basal',\n",
    "    'CREATININA': 'creatinina_basal'\n",
    "}\n",
    "\n",
    "for var_original, var_nova in variables_cliniques.items():\n",
    "    # Obtindre primera mesura vàlida per pacient\n",
    "    primera_mesura = (df_surv[df_surv['Variable'] == var_original]\n",
    "                       .sort_values(['SIPCOD', 'Fecha'])\n",
    "                       .groupby('SIPCOD')\n",
    "                       .first()['valor_numerico'])\n",
    "    \n",
    "    df_pacients[var_nova] = df_pacients['SIPCOD'].map(primera_mesura)\n",
    "    \n",
    "    if primera_mesura.notna().sum() > 0:\n",
    "        print(f\"{var_original}: {primera_mesura.notna().sum()} pacients amb dades basals\")\n",
    "\n",
    "# Afegir EuroQol\n",
    "euroqol_vars = [var for var in df_surv['Variable'].unique() if 'EQ5D' in str(var)]\n",
    "if euroqol_vars:\n",
    "    \n",
    "    # Calcular puntuació EuroQol \n",
    "    eq5d_data = (df_surv[df_surv['Variable'].isin(euroqol_vars)]\n",
    "                .sort_values(['SIPCOD', 'Fecha'])\n",
    "                .groupby('SIPCOD')\n",
    "                .agg({'valor_ordinal': 'mean'})\n",
    "                .reset_index())\n",
    "    \n",
    "    df_pacients['euroqol_basal'] = df_pacients['SIPCOD'].map(\n",
    "        eq5d_data.set_index('SIPCOD')['valor_ordinal']\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "def calcular_euroqol_espanyol(row):\n",
    "    \"\"\"Calcula l'índex EuroQol-5D segons els coeficients espanyols\"\"\"\n",
    "    cols = ['EQ5D_Movilidad', 'EQ5D_CuidadoPersonal', 'EQ5D_ActividadesHabituales', \n",
    "            'EQ5D_DolorMalestar', 'EQ5D_AnsiedadDepresion']\n",
    "    \n",
    "    # Verificar que totes les columnes existeixen i no són nul·les\n",
    "    if not all(col in row.index and pd.notna(row[col]) for col in cols):\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        valores = [int(row[col]) for col in cols]\n",
    "        m, c, a, d, an = valores\n",
    "        \n",
    "        # Si tots són 1, índex perfecte\n",
    "        if all(x == 1 for x in valores):\n",
    "            return 1.0\n",
    "        \n",
    "        # Coeficients  (EQ-5D-3L)\n",
    "        decrements = {\n",
    "            'movilidad': [0, 0.0897, 0.1794],     \n",
    "            'cuidado': [0, 0.1012, 0.2024],\n",
    "            'actividades': [0, 0.0551, 0.1102], \n",
    "            'dolor': [0, 0.0596, 0.1192],\n",
    "            'ansiedad': [0, 0.0512, 0.1024]\n",
    "        }\n",
    "        \n",
    "        # Calcular decrement total\n",
    "        decrement_total = (decrements['movilidad'][min(m-1, 2)] + \n",
    "                          decrements['cuidado'][min(c-1, 2)] + \n",
    "                          decrements['actividades'][min(a-1, 2)] + \n",
    "                          decrements['dolor'][min(d-1, 2)] + \n",
    "                          decrements['ansiedad'][min(an-1, 2)])\n",
    "        \n",
    "        # Penalització addicional si alguna dimensió és nivell 3\n",
    "        if any(x == 3 for x in valores):\n",
    "            decrement_total += 0.2119\n",
    "        \n",
    "        # Aplicar fórmula: 1 - constant - decrements\n",
    "        index_eq = 1 - 0.1502 - decrement_total\n",
    "        \n",
    "        return max(index_eq, -0.5)  # Mínim teòric\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "euroqol_vars = [var for var in df_surv['Variable'].unique() if 'EQ5D' in str(var)]\n",
    "if euroqol_vars:\n",
    "    print(f\"Variables EuroQol disponibles: {len(euroqol_vars)}\")\n",
    "    \n",
    "    # Filtrar datos EuroQol\n",
    "    eq5d_consistent = df_surv[df_surv['Variable'].isin(euroqol_vars)].copy()\n",
    "    \n",
    "    if len(eq5d_consistent) > 0:\n",
    "        # Pivot EQ5D per aplicar la fórmula\n",
    "        eq_pivot = (eq5d_consistent.pivot_table(\n",
    "            index=[\"SIPCOD\", \"Fecha\"],\n",
    "            columns=\"Variable\",\n",
    "            values=\"valor_ordinal\",\n",
    "            aggfunc=\"first\"\n",
    "        ).reset_index())\n",
    "        \n",
    "        # Aplicar fórmula índex\n",
    "        eq_pivot[\"eq_index_esp\"] = eq_pivot.apply(calcular_euroqol_espanyol, axis=1)\n",
    "        \n",
    "        # Mitjana per pacient\n",
    "        eq_per_pacient = eq_pivot.groupby('SIPCOD')['eq_index_esp'].mean()\n",
    "        \n",
    "        # Asignar índex EuroQol a cada paciente\n",
    "        df_pacients['euroqol_basal'] = df_pacients['SIPCOD'].map(eq_per_pacient)\n",
    "        \n",
    "        print(f\"EuroQol: {eq_per_pacient.notna().sum()} pacients amb dades d'índex\")\n",
    "    else:\n",
    "        df_pacients['euroqol_basal'] = np.nan\n",
    "        print(\"No hi ha dades EuroQol consistents disponibles\")\n",
    "else:\n",
    "    df_pacients['euroqol_basal'] = np.nan\n",
    "    print(\"No s'han trobat variables EuroQol\")\n",
    "\n",
    "# Netejar dataset final\n",
    "df_surv_final = df_pacients.dropna(subset=['tiempo_meses', 'evento', 'edad_años', 'ZONA_FUSIONADA']).copy()\n",
    "\n",
    "# ESTADÍSTIQUES DESCRIPTIVES\n",
    "# ===============================================================================\n",
    "# Taula descriptiva\n",
    "print(\"CARACTERÍSTIQUES BASALS:\")\n",
    "print(f\"  N total: {len(df_surv_final):,}\")\n",
    "print(f\"  Esdeveniments (morts): {df_surv_final['evento'].sum():,} ({df_surv_final['evento'].mean()*100:.1f}%)\")\n",
    "print(f\"  Temps seguiment mitjà: {df_surv_final['tiempo_meses'].median():.1f} mesos\")\n",
    "print(f\"  Rang seguiment: {df_surv_final['tiempo_meses'].min():.1f} - {df_surv_final['tiempo_meses'].max():.1f} mesos\")\n",
    "\n",
    "# Sexe\n",
    "if 'sexo' in df_surv_final.columns:\n",
    "    sexo_counts = df_surv_final['sexo'].value_counts()\n",
    "    print(f\"  Sexe: {dict(sexo_counts)}\")\n",
    "\n",
    "# Variables clíniques\n",
    "print(f\"\\nVARIABLES CLÍNIQUES BASALS:\")\n",
    "for var_col in ['rockwood_basal', 'albumina_basal', 'pcr_basal', 'creatinina_basal', 'euroqol_basal']:\n",
    "    if var_col in df_surv_final.columns:\n",
    "        var_data = df_surv_final[var_col].dropna()\n",
    "        if len(var_data) > 0:\n",
    "            print(f\"  {var_col.replace('_basal', '').upper()}:\")\n",
    "            print(f\"    Disponible: {len(var_data)} ({len(var_data)/len(df_surv_final)*100:.1f}%)\")\n",
    "            print(f\"    Mitjana ± DE: {var_data.mean():.2f} ± {var_data.std():.2f}\")\n",
    "            print(f\"    Mediana [P25-P75]: {var_data.median():.2f} [{var_data.quantile(0.25):.2f}-{var_data.quantile(0.75):.2f}]\")\n",
    "\n",
    "# ===============================================================================\n",
    "# 3. SUPERVIVÈNCIA GLOBAL - KAPLAN-MEIER\n",
    "# ===============================================================================\n",
    "# Corba Kaplan-Meier global\n",
    "kmf_global = KaplanMeierFitter()\n",
    "kmf_global.fit(df_surv_final['tiempo_meses'], df_surv_final['evento'], \n",
    "               label=f'Supervivència Global (n={len(df_surv_final)})')\n",
    "\n",
    "# Mediana supervivència\n",
    "mediana_global = kmf_global.median_survival_time_\n",
    "print(f\"Mediana supervivència: {mediana_global:.1f} mesos\" if not np.isnan(mediana_global) else \"Mediana supervivència: No assolida\")\n",
    "\n",
    "# Probabilitats supervivència\n",
    "print(\"Probabilitats supervivència:\")\n",
    "for t in [6, 12, 18, 24, 36]:\n",
    "    if t <= df_surv_final['tiempo_meses'].max():\n",
    "        try:\n",
    "            prob = kmf_global.predict(t)\n",
    "            # Buscar el temps més proper en l'índex\n",
    "            temps_proper = kmf_global.confidence_interval_survival_function_.index[\n",
    "                np.abs(kmf_global.confidence_interval_survival_function_.index - t).argmin()\n",
    "            ]\n",
    "            ic_lower, ic_upper = kmf_global.confidence_interval_survival_function_.loc[temps_proper]\n",
    "            print(f\"  {t:2d} mesos: {prob:.1%} (IC95%: {ic_lower:.1%}-{ic_upper:.1%})\")\n",
    "        except (KeyError, IndexError):\n",
    "            prob = kmf_global.predict(t)\n",
    "            print(f\"  {t:2d} mesos: {prob:.1%} (IC95%: no disponible)\")\n",
    "\n",
    "# Gràfic supervivència global\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "kmf_global.plot_survival_function(ax=ax, color='#2E86AB', linewidth=3)\n",
    "ax.fill_between(kmf_global.confidence_interval_survival_function_.index,\n",
    "                kmf_global.confidence_interval_survival_function_.iloc[:, 0],\n",
    "                kmf_global.confidence_interval_survival_function_.iloc[:, 1],\n",
    "                alpha=0.2, color='#2E86AB')\n",
    "\n",
    "ax.set_title('Corba de Supervivència Global', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Temps (mesos)', fontsize=12)\n",
    "ax.set_ylabel('Probabilitat de Supervivència', fontsize=12)\n",
    "ax.set_xticks([0, 6, 12, 18, 24] + list(range(30, 145, 10)))\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "# Afegir \n",
    "ax.text(0.02, 0.98, f'N = {len(df_surv_final):,}\\nEsdeveniments = {df_surv_final[\"evento\"].sum():,} ({df_surv_final[\"evento\"].mean()*100:.1f}%)', \n",
    "        transform=ax.transAxes, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# DEFINICIÓ DE FUNCIONS AUXILIARS\n",
    "# ===============================================================================\n",
    "\n",
    "def analitzar_supervivencia_grups(df, variable, titol, categories=None, colors=None):\n",
    "    \"\"\"Funció per a anàlisi supervivència per grups amb corbes KM\"\"\"\n",
    "    \n",
    "    if variable not in df.columns:\n",
    "        print(f\"Variable {variable} no disponible\")\n",
    "        return\n",
    "    \n",
    "    # Filtrar dades vàlides\n",
    "    df_grup = df.dropna(subset=[variable, 'tiempo_meses', 'evento']).copy()\n",
    "    \n",
    "    if categories is not None:\n",
    "        # Convertir a category si no ho és\n",
    "        if not hasattr(df_grup[variable], 'cat'):\n",
    "            df_grup[variable] = df_grup[variable].astype('category')\n",
    "        \n",
    "        # Reordenar categories\n",
    "        df_grup[variable] = df_grup[variable].cat.reorder_categories(categories)\n",
    "        grups = categories\n",
    "    else:\n",
    "        # Si no hi ha categories especificades, usar l'ordre original\n",
    "        if hasattr(df_grup[variable], 'cat'):\n",
    "            grups = df_grup[variable].cat.categories\n",
    "        else:\n",
    "            grups = sorted(df_grup[variable].unique())\n",
    "    \n",
    "    if len(grups) < 2:\n",
    "        print(f\"Grups insuficients per a {variable}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{titol}:\")\n",
    "    \n",
    "    # Colors\n",
    "    if colors is None:\n",
    "        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']\n",
    "    \n",
    "    # Crear gràfics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Corbes Kaplan-Meier\n",
    "    kmf = KaplanMeierFitter()\n",
    "    resultats_grups = []\n",
    "    \n",
    "    for i, grup in enumerate(grups):\n",
    "        if i >= len(colors):\n",
    "            break\n",
    "            \n",
    "        data_grup = df_grup[df_grup[variable] == grup]\n",
    "        n_grup = len(data_grup)\n",
    "        events_grup = data_grup['evento'].sum()\n",
    "        \n",
    "        if n_grup >= 5:  # Mínim 5 pacients\n",
    "            kmf.fit(data_grup['tiempo_meses'], data_grup['evento'],\n",
    "                   label=f'{grup} (n={n_grup})')\n",
    "            kmf.plot_survival_function(ax=axes[0], color=colors[i], linewidth=2.5)\n",
    "            \n",
    "            # Estadístiques\n",
    "            mediana = kmf.median_survival_time_\n",
    "            try:\n",
    "                prob_12m = kmf.predict(12) if 12 <= data_grup['tiempo_meses'].max() else None\n",
    "            except:\n",
    "                prob_12m = None\n",
    "            try:\n",
    "                prob_24m = kmf.predict(24) if 24 <= data_grup['tiempo_meses'].max() else None\n",
    "            except:\n",
    "                prob_24m = None\n",
    "            \n",
    "            resultats_grups.append({\n",
    "                'grup': grup,\n",
    "                'n': n_grup,\n",
    "                'events': events_grup,\n",
    "                'tasa_events': events_grup/n_grup*100,\n",
    "                'mediana': mediana if not np.isnan(mediana) else None,\n",
    "                'prob_12m': prob_12m,\n",
    "                'prob_24m': prob_24m\n",
    "            })\n",
    "    \n",
    "    # Configurar gràfic corbes\n",
    "    axes[0].set_title(titol, fontsize=14, fontweight='bold', pad=20)\n",
    "    axes[0].set_xlabel('Temps (mesos)')\n",
    "    axes[0].set_ylabel('Probabilitat Supervivència')\n",
    "    axes[0].set_xticks([0, 6, 12, 18, 24] + list(range(30, 145, 10)))\n",
    "    axes[0].legend(loc='upper right')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_ylim(0, 1.05)\n",
    "    \n",
    "    # Gràfic taxes esdeveniments\n",
    "    if resultats_grups:\n",
    "        df_res = pd.DataFrame(resultats_grups)\n",
    "        \n",
    "        bars = axes[1].bar(range(len(df_res)), df_res['tasa_events'],\n",
    "                          color=colors[:len(df_res)], alpha=0.8, edgecolor='black')\n",
    "        \n",
    "        axes[1].set_xticks(range(len(df_res)))\n",
    "        axes[1].set_xticklabels(df_res['grup'], rotation=45, ha='right')\n",
    "        axes[1].set_ylabel('Taxa Esdeveniments (%)')\n",
    "        axes[1].set_title('Taxa Esdeveniments per Grup', fontweight='bold', pad=20)\n",
    "        axes[1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Afegir valors en barres\n",
    "        for bar, tasa, n in zip(bars, df_res['tasa_events'], df_res['n']):\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(df_res['tasa_events'])*0.02,\n",
    "                        f'{tasa:.1f}%\\n(n={n})', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Test log-rank\n",
    "    if len(grups) >= 2 and len(df_grup) > 20:\n",
    "        try:\n",
    "            # Test bivariant entre dos grups principals\n",
    "            grup1, grup2 = grups[0], grups[1]\n",
    "            \n",
    "            data1 = df_grup[df_grup[variable] == grup1]\n",
    "            data2 = df_grup[df_grup[variable] == grup2]\n",
    "            \n",
    "            if len(data1) >= 5 and len(data2) >= 5:\n",
    "                result = logrank_test(\n",
    "                    data1['tiempo_meses'], data2['tiempo_meses'],\n",
    "                    data1['evento'], data2['evento']\n",
    "                )\n",
    "                \n",
    "                print(f\"  Test Log-rank ({grup1} vs {grup2}): p = {result.p_value:.4f}\")\n",
    "                if result.p_value < 0.05:\n",
    "                    print(f\"   Diferències significatives entre grups\")\n",
    "                else:\n",
    "                    print(f\"   No hi ha diferències significatives\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error en test log-rank: {str(e)[:50]}\")\n",
    "    \n",
    "    # Mostrar estadístiques\n",
    "    if resultats_grups:\n",
    "        print(f\"  Estadístiques per grup:\")\n",
    "        for res in resultats_grups:\n",
    "            mediana_str = f\"{res['mediana']:.1f} mesos\" if res['mediana'] else \"No assolida\"\n",
    "            print(f\"    {res['grup']}: {res['events']}/{res['n']} events ({res['tasa_events']:.1f}%), mediana: {mediana_str}\")\n",
    "\n",
    "# ANÀLISI PER GRUPS (CORBES SUPERVIVÈNCIA)\n",
    "# ===============================================================================\n",
    "# Crear grups per a anàlisi \n",
    "\n",
    "# Grups d'edat\n",
    "df_surv_final['grup_edat'] = pd.cut(df_surv_final['edad_años'], \n",
    "                                    bins=[0, 70, 80, 90, 150],\n",
    "                                    labels=['<70 anys', '70-80 anys', '80-90 anys', '>90 anys'], ordered=True)\n",
    "\n",
    "analitzar_supervivencia_grups(df_surv_final, 'grup_edat', 'Supervivència per Edat')\n",
    "\n",
    "# Grups sexe\n",
    "if 'sexo' in df_surv_final.columns:\n",
    "    df_surv_final['grup_sexe'] = df_surv_final['sexo'].map({'1': 'Homes', '2': 'Dones'})\n",
    "    analitzar_supervivencia_grups(df_surv_final, 'grup_sexe', 'Supervivència per Sexe', \n",
    "                                 colors=['#2E86AB', '#F18F01'])\n",
    "\n",
    "# Grups fragilitat\n",
    "if 'rockwood_basal' in df_surv_final.columns and df_surv_final['rockwood_basal'].notna().sum() > 30:\n",
    "    rockwood_stats = df_surv_final['rockwood_basal'].describe()\n",
    "    print(f\"\\nEstadístiques Rockwood: min={rockwood_stats['min']:.2f}, max={rockwood_stats['max']:.2f}\")\n",
    "    \n",
    "    q25, q50, q75 = df_surv_final['rockwood_basal'].quantile([0.25, 0.5, 0.75])\n",
    "    df_surv_final['grup_rockwood'] = pd.cut(df_surv_final['rockwood_basal'],\n",
    "                                           bins=[0, q25, q75, 1.0],\n",
    "                                           labels=[f'Fragilitat dèbil (≤{q25:.2f})', \n",
    "                                                  f'Fragilitat moderada ({q25:.2f}-{q75:.2f})', \n",
    "                                                  f'Fragilitat severa (>{q75:.2f})'],ordered=True)\n",
    "    \n",
    "    analitzar_supervivencia_grups(df_surv_final, 'grup_rockwood', 'Supervivència per Fragilitat (Rockwood)')\n",
    "\n",
    "# Grups albúmina\n",
    "if 'albumina_basal' in df_surv_final.columns and df_surv_final['albumina_basal'].notna().sum() > 30:\n",
    "    df_surv_final['grup_albumina'] = pd.cut(df_surv_final['albumina_basal'],\n",
    "                                           bins=[0, 3.0, 3.5, 10],\n",
    "                                           labels=['Desnutrició (<3.0)', 'Límit (3.0-3.5)', 'Normal (>3.5)'], ordered=True)\n",
    "    \n",
    "    analitzar_supervivencia_grups(df_surv_final, 'grup_albumina', 'Supervivència per Albúmina')\n",
    "\n",
    "# Grups PCR\n",
    "if 'pcr_basal' in df_surv_final.columns and df_surv_final['pcr_basal'].notna().sum() > 30:\n",
    "    df_surv_final['grup_pcr'] = pd.cut(df_surv_final['pcr_basal'],\n",
    "                                       bins=[0, 10, 50, 1000],\n",
    "                                       labels=['Normal (<10)', 'Elevada (10-50)', 'Molt elevada (>50)'], ordered=True)\n",
    "    \n",
    "    analitzar_supervivencia_grups(df_surv_final, 'grup_pcr', 'Supervivència per PCR (Inflamació)')\n",
    "\n",
    "# Grups creatinina\n",
    "if 'creatinina_basal' in df_surv_final.columns and df_surv_final['creatinina_basal'].notna().sum() > 30:\n",
    "    df_surv_final['grup_creatinina'] = pd.cut(df_surv_final['creatinina_basal'],\n",
    "                                              bins=[0, 1.2, 2.0, 20],\n",
    "                                              labels=['Normal (<1.2)', 'Elevada (1.2-2.0)', 'Molt elevada (>2.0)'], ordered=True)\n",
    "    \n",
    "    analitzar_supervivencia_grups(df_surv_final, 'grup_creatinina', 'Supervivència per Creatinina')\n",
    "\n",
    "# Grups EuroQol (qualitat de vida)\n",
    "if 'euroqol_basal' in df_surv_final.columns and df_surv_final['euroqol_basal'].notna().sum() > 30:\n",
    "    eq_q25, eq_q75 = df_surv_final['euroqol_basal'].quantile([0.25, 0.75])\n",
    "    df_surv_final['grup_euroqol'] = pd.cut(df_surv_final['euroqol_basal'],\n",
    "                                           bins=[0, eq_q25, eq_q75, 5],\n",
    "                                           labels=[f'Baixa QV(<{eq_q25:.2f})', \n",
    "                                                  f'Moderada QV ({eq_q25:.1f}-{eq_q75:.2f})', \n",
    "                                                  f'Alta QV(>{eq_q75:.2f})'], ordered=True)\n",
    "    \n",
    "    analitzar_supervivencia_grups(df_surv_final, 'grup_euroqol', 'Supervivència per Qualitat de Vida (EuroQol)')\n",
    "\n",
    "# Anàlisi per tipus de pacient\n",
    "if 'TIPO_PACIENTE_FUSIONADO' in df_surv_final.columns:\n",
    "    tipus_freq = df_surv_final['TIPO_PACIENTE_FUSIONADO'].value_counts()\n",
    "    tipus_principals = tipus_freq[tipus_freq >= 50].index[:6]\n",
    "    \n",
    "    if len(tipus_principals) >= 2:\n",
    "        df_tipus = df_surv_final[df_surv_final['TIPO_PACIENTE_FUSIONADO'].isin(tipus_principals)].copy()\n",
    "        print(f\"\\nTipus de pacient analitzats: {len(tipus_principals)}\")\n",
    "        for tipus in tipus_principals:\n",
    "            n_tipus = (df_tipus['TIPO_PACIENTE_FUSIONADO'] == tipus).sum()\n",
    "            print(f\"  {tipus}: {n_tipus} pacients\")\n",
    "        \n",
    "        analitzar_supervivencia_grups(df_tipus, 'TIPO_PACIENTE_FUSIONADO',\n",
    "                                     'Supervivència per Tipus de Patologia')\n",
    "\n",
    "# Anàlisi per hospital\n",
    "if 'HOSPITAL_FUSIONADO' in df_surv_final.columns:\n",
    "    hospitals_freq = df_surv_final['HOSPITAL_FUSIONADO'].value_counts()\n",
    "    hospitals_principals = hospitals_freq[hospitals_freq >= 100].index[:5]\n",
    "    \n",
    "    if len(hospitals_principals) >= 2:\n",
    "        df_hospitals = df_surv_final[df_surv_final['HOSPITAL_FUSIONADO'].isin(hospitals_principals)].copy()\n",
    "        print(f\"\\nHospitals analitzats: {len(hospitals_principals)}\")\n",
    "        \n",
    "        analitzar_supervivencia_grups(df_hospitals, 'HOSPITAL_FUSIONADO',\n",
    "                                     'Supervivència per Hospital')\n",
    "\n",
    "# ===============================================================================\n",
    "# 5. ESTRATIFICACIÓ DE RISC\n",
    "# ===============================================================================\n",
    "\n",
    "# Score clínic  \n",
    "df_surv_final['score_clinico'] = 0\n",
    "factors_inclosos = []\n",
    "\n",
    "# Edat >85 anys\n",
    "edad_p75 = df_surv_final['edad_años'].quantile(0.75)\n",
    "df_surv_final['score_clinico'] += (df_surv_final['edad_años'] > 90).astype(int)\n",
    "factors_inclosos.append(f\"Edat > 90 anys\")\n",
    "\n",
    "# Sexe masculí \n",
    "if 'sexo_masculino' in df_surv_final.columns:\n",
    "    df_surv_final['score_clinico'] += df_surv_final['sexo_masculino'].fillna(0).astype(int)\n",
    "    factors_inclosos.append(\"Sexe masculí\")\n",
    "elif 'sexo' in df_surv_final.columns:\n",
    "    df_surv_final['score_clinico'] += (df_surv_final['sexo'] == '1').fillna(False).astype(int)\n",
    "    factors_inclosos.append(\"Sexe masculí\")\n",
    "\n",
    "# Tipus de Pacient\n",
    "if 'TIPO_PACIENTE_FUSIONADO' in df_surv_final.columns:\n",
    "    df_surv_final['score_clinico'] += (df_surv_final['TIPO_PACIENTE_FUSIONADO'] == 'Paliativo oncológico').fillna(False).astype(int)\n",
    "    factors_inclosos.append(\"Pacient pal·liatiu oncològic\")\n",
    "\n",
    "# Fragilitat alta \n",
    "if 'rockwood_basal' in df_surv_final.columns:\n",
    "    rockwood_p75 = df_surv_final['rockwood_basal'].quantile(0.75)\n",
    "    df_surv_final['score_clinico'] += (df_surv_final['rockwood_basal'] > 0.5).fillna(False).astype(int)\n",
    "    factors_inclosos.append(f\"Rockwood > 0.5\")\n",
    "\n",
    "# Albúmina baixa\n",
    "if 'albumina_basal' in df_surv_final.columns:\n",
    "    df_surv_final['score_clinico'] += (df_surv_final['albumina_basal'] < 3.0).fillna(False).astype(int)\n",
    "    factors_inclosos.append(\"Albúmina < 3.0\")\n",
    "\n",
    "# PCR alta\n",
    "if 'pcr_basal' in df_surv_final.columns:\n",
    "    pcr_p75 = df_surv_final['pcr_basal'].quantile(0.75)\n",
    "    df_surv_final['score_clinico'] += (df_surv_final['pcr_basal'] > 50.0).fillna(False).astype(int)\n",
    "    factors_inclosos.append(f\"PCR > 50.0\")\n",
    "\n",
    "# Creatinina alta\n",
    "if 'creatinina_basal' in df_surv_final.columns:\n",
    "    df_surv_final['score_clinico'] += (df_surv_final['creatinina_basal'] > 2.0).fillna(False).astype(int)\n",
    "    factors_inclosos.append(\"Creatinina > 2.0\")\n",
    "\n",
    "if 'euroqol_basal' in df_surv_final.columns:\n",
    "    df_surv_final['score_clinico'] += (df_surv_final['euroqol_basal'] < 0.18).fillna(False).astype(int)\n",
    "    factors_inclosos.append(\"EuroQol < 0.18\")\n",
    "\n",
    "if len(factors_inclosos) >= 3:\n",
    "    print(f\"  Factors inclosos: {', '.join(factors_inclosos)}\")\n",
    "    \n",
    "    # Distribució del score\n",
    "    score_dist = df_surv_final['score_clinico'].value_counts()\n",
    "    print(f\"  Distribució score:\")\n",
    "    for score, count in score_dist.items():\n",
    "        print(f\"    {score} factors: {count} pacients ({count/len(df_surv_final)*100:.1f}%)\")\n",
    "    \n",
    "    # Crear grups de risc clínic\n",
    "    conditions = [\n",
    "        (df_surv_final['score_clinico'] <= 1),\n",
    "        (df_surv_final['score_clinico'] == 2),\n",
    "        (df_surv_final['score_clinico'] >= 3)\n",
    "    ]\n",
    "    choices = ['Baix (0-1 factors)', 'Intermedi (2 factors)', 'Sever (≥3 factors)']\n",
    "    \n",
    "    df_surv_final['riesgo_clinico'] = np.select(conditions, choices, default='Sense classificar')\n",
    "   \n",
    "    # Anàlisi supervivència per score clínic\n",
    "    analitzar_supervivencia_grups(df_surv_final, 'riesgo_clinico',\n",
    "                                 'Supervivència per Score Clínic de Risc',\n",
    "                                 colors=['#2ca02c', '#ff7f0e','#d62728'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603968e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuració d'estil\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "\n",
    "\n",
    "# APLICAR FILTRE DE TIPUS DE PACIENT\n",
    "# ===============================================================================\n",
    "\n",
    "\n",
    "# Llistat de tipus de pacient a conservar\n",
    "tipus_a_mantenir = [\n",
    "    \"Crónico pluripatológico\",\n",
    "    \"Paliativo no oncológico\", \n",
    "    \"Paliativo oncológico\"\n",
    "]\n",
    "\n",
    "# Aplicar el filtre\n",
    "if hasattr(df_clean, 'to_pandas'):\n",
    "    df_work = df_clean.to_pandas()\n",
    "else:\n",
    "    df_work = df_clean.copy()\n",
    "\n",
    "print(f\"Dataset original: {len(df_work)} registres\")\n",
    "\n",
    "# Filtrar per tipus de pacient\n",
    "df_filtrat = df_work[df_work['TIPO_PACIENTE_FUSIONADO'].isin(tipus_a_mantenir)].copy()\n",
    "\n",
    "print(f\"Dataset filtrat: {len(df_filtrat)} registres\")\n",
    "\n",
    "print(f\"\\nDistribució per tipus de pacient:\")\n",
    "tipus_counts = df_filtrat['TIPO_PACIENTE_FUSIONADO'].value_counts()\n",
    "for tipus, count in tipus_counts.items():\n",
    "    print(f\"  {tipus}: {count:,} ({count/len(df_filtrat)*100:.1f}%)\")\n",
    "\n",
    "#PREPARACIÓ DE DATASET PER PACIENT\n",
    "# ===============================================================================\n",
    "\n",
    "# Crear dataset per pacient\n",
    "df_pacients = df_filtrat.groupby('SIPCOD').agg({\n",
    "    'edad_dias_medicion': 'first',\n",
    "    'fallecido': 'first',\n",
    "    'tiempo_supervivencia': 'first', \n",
    "    'sexo': 'first',\n",
    "    'TIPO_PACIENTE_FUSIONADO': 'first',\n",
    "    'HOSPITAL_FUSIONADO': 'first',\n",
    "    'ZONA_FUSIONADA': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Conversions temporals\n",
    "df_pacients['edat_anys'] = df_pacients['edad_dias_medicion'] / 365.25\n",
    "df_pacients['temps_mesos'] = df_pacients['tiempo_supervivencia'] / 30.44\n",
    "df_pacients['event'] = df_pacients['fallecido'].astype(int)\n",
    "\n",
    "print(f\"Pacients únics: {len(df_pacients)}\")\n",
    "\n",
    "# Mostrar informació de la variable edat_anys\n",
    "if 'edat_anys' in df_pacients.columns:\n",
    "    edat_valida = df_pacients['edat_anys'].dropna()\n",
    "    if len(edat_valida) > 0:\n",
    "        print(f\"\\nEDAT_ANYS:\")\n",
    "        print(f\"  N vàlids: {len(edat_valida)}\")\n",
    "        print(f\"  Rang: {edat_valida.min():.2f} - {edat_valida.max():.2f} anys\")\n",
    "        print(f\"  Mitjana ± DE: {edat_valida.mean():.2f} ± {edat_valida.std():.2f}\")\n",
    "        print(f\"  Mediana [P25-P75]: {edat_valida.median():.2f} [{edat_valida.quantile(0.25):.2f}-{edat_valida.quantile(0.75):.2f}]\")\n",
    "\n",
    "# ANÀLISI I CORRECCIÓ D'ESCALES CLÍNIQUES\n",
    "# ===============================================================================\n",
    "# Obtindre valors basals (primera mesura per pacient)\n",
    "variables_cliniques = {\n",
    "    'Rockwood': 'rockwood_basal',\n",
    "    'ALBUMINA': 'albumina_basal',\n",
    "    'PCR': 'pcr_basal', \n",
    "    'CREATININA': 'creatinina_basal'\n",
    "}\n",
    "\n",
    "for var_original, var_nova in variables_cliniques.items():\n",
    "    primera_mesura = (df_filtrat[df_filtrat['Variable'] == var_original]\n",
    "                      .sort_values(['SIPCOD', 'Fecha'])\n",
    "                      .groupby('SIPCOD')\n",
    "                      .first()['valor_numerico'])\n",
    "    \n",
    "    df_pacients[var_nova] = df_pacients['SIPCOD'].map(primera_mesura)\n",
    "    \n",
    "    if primera_mesura.notna().sum() > 0:\n",
    "        valors_valids = primera_mesura.dropna()\n",
    "        print(f\"\\n{var_original}:\")\n",
    "        print(f\"  N vàlids: {len(valors_valids)}\")\n",
    "        print(f\"  Rang: {valors_valids.min():.3f} - {valors_valids.max():.3f}\")\n",
    "        print(f\"  Mitjana ± DE: {valors_valids.mean():.3f} ± {valors_valids.std():.3f}\")\n",
    "        print(f\"  Mediana [P25-P75]: {valors_valids.median():.3f} [{valors_valids.quantile(0.25):.3f}-{valors_valids.quantile(0.75):.3f}]\")\n",
    "\n",
    "# EuroQol \n",
    "def calcular_euroqol_espanyol(row):\n",
    "    \"\"\"Calcula l'índex EuroQol-5D segons els coeficients espanyols\"\"\"\n",
    "    cols = ['EQ5D_Movilidad', 'EQ5D_CuidadoPersonal', 'EQ5D_ActividadesHabituales', \n",
    "            'EQ5D_DolorMalestar', 'EQ5D_AnsiedadDepresion']\n",
    "    \n",
    "    # Verificar que totes les columnes existeixen i no són nul·les\n",
    "    if not all(col in row.index and pd.notna(row[col]) for col in cols):\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        valors = [int(row[col]) for col in cols]\n",
    "        m, c, a, d, an = valors\n",
    "        \n",
    "        # Si tots són 1, índex perfecte\n",
    "        if all(x == 1 for x in valors):\n",
    "            return 1.0\n",
    "        \n",
    "        # Coeficients  (EQ-5D-3L)\n",
    "        decrements = {\n",
    "            'movilitat': [0, 0.0897, 0.1794],      \n",
    "            'cuidat': [0, 0.1012, 0.2024],\n",
    "            'activitats': [0, 0.0551, 0.1102], \n",
    "            'dolor': [0, 0.0596, 0.1192],\n",
    "            'ansietat': [0, 0.0512, 0.1024]\n",
    "        }\n",
    "        \n",
    "        # Calcular decrement total\n",
    "        decrement_total = (decrements['movilitat'][min(m-1, 2)] + \n",
    "                          decrements['cuidat'][min(c-1, 2)] + \n",
    "                          decrements['activitats'][min(a-1, 2)] + \n",
    "                          decrements['dolor'][min(d-1, 2)] + \n",
    "                          decrements['ansietat'][min(an-1, 2)])\n",
    "        \n",
    "        # Penalització addicional si alguna dimensió és nivell 3\n",
    "        if any(x == 3 for x in valors):\n",
    "            decrement_total += 0.2119\n",
    "        \n",
    "        # Aplicar fórmula: 1 - constant - decrements\n",
    "        index_eq = 1 - 0.1502 - decrement_total\n",
    "        \n",
    "        # L'índex negatiu (estats pitjors que la mort)\n",
    "        return max(index_eq, -0.5)  # Mínim teòric\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "euroqol_vars = [var for var in df_filtrat['Variable'].unique() if 'EQ5D' in str(var)]\n",
    "\n",
    "if euroqol_vars:\n",
    "    eq5d_data = (df_filtrat[df_filtrat['Variable'].isin(euroqol_vars)]\n",
    "                .sort_values(['SIPCOD', 'Fecha'])\n",
    "                .groupby('SIPCOD')\n",
    "                .agg({'valor_ordinal': 'mean'})\n",
    "                .reset_index())\n",
    "    \n",
    "if euroqol_vars:\n",
    "    # Crear un pivot per tindre les dimensions com a columnes\n",
    "    eq5d_pivot = (df_filtrat[df_filtrat['Variable'].isin(euroqol_vars)]\n",
    "                  .pivot_table(index='SIPCOD', \n",
    "                             columns='Variable', \n",
    "                             values='valor_ordinal',\n",
    "                             aggfunc='first')  # o 'mean' si hi ha múltiples valors\n",
    "                  .reset_index())\n",
    "    \n",
    "    # Aplicar la funció a cada fila\n",
    "    eq5d_pivot['euroqol_basal'] = eq5d_pivot.apply(calcular_euroqol_espanyol, axis=1)\n",
    "    \n",
    "    # Mapejar al df principal\n",
    "    df_pacients['euroqol_basal'] = df_pacients['SIPCOD'].map(\n",
    "        eq5d_pivot.set_index('SIPCOD')['euroqol_basal']\n",
    "    )\n",
    "\n",
    "    euroqol_valids = df_pacients['euroqol_basal'].dropna()\n",
    "    if len(euroqol_valids) > 0:\n",
    "        print(f\"\\nEUROQOL:\")\n",
    "        print(f\"  N vàlids: {len(euroqol_valids)}\")\n",
    "        print(f\"  Rang: {euroqol_valids.min():.3f} - {euroqol_valids.max():.3f}\")\n",
    "        print(f\"  Mitjana ± DE: {euroqol_valids.mean():.3f} ± {euroqol_valids.std():.3f}\")\n",
    "\n",
    "# DETECCIÓ DE PROBLEMES D'ESCALA I CORRECCIÓ\n",
    "# ===============================================================================\n",
    "\n",
    "df_corregit = df_pacients.copy()\n",
    "\n",
    "# EDAT: Verificar que està en anys (rang esperat 0-120)\n",
    "if 'edat_anys' in df_corregit.columns:\n",
    "    edat_orig = df_corregit['edat_anys'].dropna()\n",
    "    if len(edat_orig) > 0:\n",
    "        print(f\" EDAT: Rang {edat_orig.min():.2f} - {edat_orig.max():.2f} anys\")\n",
    "        if edat_orig.min() >= 0 and edat_orig.max() <= 120:\n",
    "            print(\"    Valors raonables per edat en anys\")\n",
    "        else:\n",
    "            print(\"     Valors fora del rang fisiològic esperat (0-120 anys)\")\n",
    "        \n",
    "        print(f\"   Mitjana: {edat_orig.mean():.1f} anys\")\n",
    "        print(f\"   Mediana: {edat_orig.median():.1f} anys\")\n",
    "\n",
    "# ROCKWOOD:\n",
    "if 'rockwood_basal' in df_corregit.columns:\n",
    "    rockwood_orig = df_corregit['rockwood_basal'].dropna()\n",
    "    if len(rockwood_orig) > 0 and rockwood_orig.max() <= 1.0:\n",
    "        # Mantenir l'escala\n",
    "        df_corregit['rockwood_basal'] = df_corregit['rockwood_basal'] \n",
    "        \n",
    "        rockwood_corr = df_corregit['rockwood_basal'].dropna()\n",
    "        print(f\"   Escala original: {rockwood_orig.min():.3f} - {rockwood_orig.max():.3f}\")\n",
    "        print(f\"   Escala mantinguda: {rockwood_corr.min():.3f} - {rockwood_corr.max():.3f}\")\n",
    "        print(f\"   Interpretació: 0=Molt Fit, 1=Terminalment malalt\")\n",
    "    else:\n",
    "        df_corregit['rockwood_basal'] = df_corregit['rockwood_basal']\n",
    "\n",
    "# ALBÚMINA: Verificar escala g/dL (normal 3.5-5.0)\n",
    "if 'albumina_basal' in df_corregit.columns:\n",
    "    albumina_orig = df_corregit['albumina_basal'].dropna()\n",
    "    if len(albumina_orig) > 0:\n",
    "        print(f\" ALBÚMINA: Rang {albumina_orig.min():.2f} - {albumina_orig.max():.2f} g/dL\")\n",
    "        df_corregit['albumina_basal'] = df_corregit['albumina_basal']\n",
    "        if albumina_orig.min() < 1.0 or albumina_orig.max() > 6.0:\n",
    "            print(\"     Valors fora del rang fisiològic esperat\")\n",
    "\n",
    "# PCR: Verificar escala mg/L\n",
    "if 'pcr_basal' in df_corregit.columns:\n",
    "    pcr_orig = df_corregit['pcr_basal'].dropna()\n",
    "    if len(pcr_orig) > 0:\n",
    "        print(f\" PCR: Rang {pcr_orig.min():.2f} - {pcr_orig.max():.2f} mg/L\")\n",
    "        df_corregit['pcr_basal'] = df_corregit['pcr_basal']\n",
    "\n",
    "# CREATININA: Verificar escala mg/dL (normal 0.6-1.2)\n",
    "if 'creatinina_basal' in df_corregit.columns:\n",
    "    creatinina_orig = df_corregit['creatinina_basal'].dropna()\n",
    "    if len(creatinina_orig) > 0:\n",
    "        print(f\" CREATININA: Rang {creatinina_orig.min():.2f} - {creatinina_orig.max():.2f} mg/dL\")\n",
    "        df_corregit['creatinina_basal'] = df_corregit['creatinina_basal']\n",
    "\n",
    "# EUROQOL: Verificar escala (hauria d'estar 0-1 o negatiu)\n",
    "if 'euroqol_basal' in df_corregit.columns:\n",
    "    euroqol_orig = df_corregit['euroqol_basal'].dropna()\n",
    "    if len(euroqol_orig) > 0:\n",
    "        print(f\" EUROQOL: Rang {euroqol_orig.min():.3f} - {euroqol_orig.max():.3f}\")\n",
    "        df_corregit['euroqol_basal'] = df_corregit['euroqol_basal']\n",
    "\n",
    "# ANÀLISI DE COL·LINEALITAT\n",
    "# ===============================================================================\n",
    "\n",
    "# Seleccionar variables clíniques corregides per anàlisi\n",
    "variables_numeriques = ['edat_anys']\n",
    "if 'sexo' in df_corregit.columns:\n",
    "    df_corregit['sexe_masculi'] = (df_corregit['sexo'] == '1').astype(int)\n",
    "    variables_numeriques.append('sexe_masculi')\n",
    "\n",
    "# Afegir variables clíniques corregides disponibles\n",
    "variables_cliniques_corregides = []\n",
    "for var in ['rockwood_basal', 'albumina_basal', \n",
    "           'pcr_basal', 'creatinina_basal', 'euroqol_basal']:\n",
    "    if var in df_corregit.columns and df_corregit[var].notna().sum() > 50:\n",
    "        variables_cliniques_corregides.append(var)\n",
    "\n",
    "totes_variables = variables_numeriques + variables_cliniques_corregides\n",
    "\n",
    "print(f\"Variables per anàlisi: {len(totes_variables)}\")\n",
    "for var in totes_variables:\n",
    "    n_valids = df_corregit[var].notna().sum()\n",
    "    print(f\"  {var}: {n_valids} valors vàlids\")\n",
    "\n",
    "# Dataset complet per anàlisi\n",
    "df_complet = df_corregit[totes_variables + ['temps_mesos', 'event']].dropna()\n",
    "print(f\"\\nDataset complet: {len(df_complet)} pacients\")\n",
    "\n",
    "# VARIABLES PER REGRESSIÓ\n",
    "# ===============================================================================\n",
    "\n",
    "df_sense_estandarditzar = df_complet.copy()\n",
    "\n",
    "print(f\"Variables:\")\n",
    "print(f\"  - Creatinina: unitats mg/dL\")\n",
    "print(f\"  - PCR: unitats mg/L\") \n",
    "print(f\"  - Albúmina: unitats g/dL\")\n",
    "print(f\"  - Rockwood: escala 0-1\")\n",
    "print(f\"  - EuroQol: escala -0.5 a 1.0\")\n",
    "print(f\"  - Edat: anys\")\n",
    "print(f\"  - Sexe: variable dicotòmica\")\n",
    "\n",
    "# Crear llista final de variables per Cox\n",
    "variables_cox_originals = (['edat_anys'] + \n",
    "                          [v for v in variables_numeriques if 'sexe' in v] + \n",
    "                          variables_cliniques_corregides)\n",
    "\n",
    "print(f\"\\nVariables per model Cox: {len(variables_cox_originals)}\")\n",
    "for var in variables_cox_originals:\n",
    "    print(f\"  - {var}\")\n",
    "\n",
    "# MODELS DE COX\n",
    "# ===============================================================================\n",
    "\n",
    "variables_cox_finals = [v for v in variables_cox_originals if v != 'sexe_masculi' or df_complet[v].sum() > 10]\n",
    "\n",
    "try:\n",
    "    cph_original = CoxPHFitter()\n",
    "    df_cox_orig = df_sense_estandarditzar[variables_cox_finals + ['temps_mesos', 'event']].dropna()\n",
    "    \n",
    "    print(f\"  N pacients: {len(df_cox_orig)}\")\n",
    "    \n",
    "    cph_original.fit(df_cox_orig, duration_col='temps_mesos', event_col='event')\n",
    "    \n",
    "    print(\"  RESULTATS:\")\n",
    "    print(\"  \" + \"=\"*50)\n",
    "    \n",
    "    summary_orig = cph_original.summary\n",
    "    for var, row in summary_orig.iterrows():\n",
    "        hr = np.exp(row['coef'])\n",
    "        ic_low = np.exp(row['coef lower 95%'])\n",
    "        ic_high = np.exp(row['coef upper 95%'])\n",
    "        \n",
    "        significatiu = \"***\" if row['p'] < 0.001 else \"**\" if row['p'] < 0.01 else \"*\" if row['p'] < 0.05 else \"\"\n",
    "        \n",
    "        print(f\"    {var}: HR={hr:.3f} (IC95%: {ic_low:.3f}-{ic_high:.3f}) p={row['p']:.4f} {significatiu}\")\n",
    "        \n",
    "        # Interpretacions específiques per variable\n",
    "        if 'rockwood' in var.lower():\n",
    "            print(f\"       Interpretació: per cada 1 punt d'increment en fragilitat\")\n",
    "        elif 'creatinina' in var.lower():\n",
    "            print(f\"       Interpretació: per cada 1 mg/dL d'increment\")\n",
    "        elif 'pcr' in var.lower():\n",
    "            print(f\"       Interpretació: per cada 1 mg/L d'increment\")\n",
    "        elif 'albumina' in var.lower():\n",
    "            print(f\"       Interpretació: per cada 1 g/dL d'increment\")\n",
    "        elif 'euroqol' in var.lower():\n",
    "            print(f\"       Interpretació: per cada 0.1 punt d'increment en qualitat de vida\")\n",
    "        elif 'edat' in var.lower():\n",
    "            print(f\"       Interpretació: per cada any d'increment\")\n",
    "    \n",
    "    print(f\"  C-index: {cph_original.concordance_index_:.3f}\")\n",
    "    \n",
    "    # Forest plot del model sense estandarditzar\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    cph_original.plot(ax=ax, hazard_ratios=True)\n",
    "    ax.set_title('Gràfic Forest - Model Sense Estandarditzar\\nHazard Ratios (IC 95%)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    ax.axvline(x=1, color='red', linestyle='--', alpha=0.7, linewidth=2)\n",
    "    ax.set_xlabel('Hazard Ratio')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  Error en model original: {str(e)}\")\n",
    "    cph_original = None\n",
    "\n",
    "# ANÀLISI DE MULTICOL·LINEALITAT \n",
    "# ===============================================================================\n",
    "\n",
    "print(f\"\\n8. ELIMINACIÓ DE MULTICOL·LINEALITAT SEVERA\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if 'cph_original' in locals() and cph_original is not None:\n",
    "    \n",
    "    print(f\"\\n CRITERIS D'INTERPRETACIÓ DEL VIF:\")\n",
    "    print(f\"   VIF < 2.5:   Cap problema de multicol·linealitat\")\n",
    "    print(f\"   VIF 2.5-5:   Multicol·linealitat lleugera\")\n",
    "    print(f\"   VIF 5-10:    Multicol·linealitat moderada\")\n",
    "    print(f\"   VIF > 10:    Multicol·linealitat severa\")\n",
    "    \n",
    "    # Identificar només variables amb VIF > 10 (multicol·linealitat severa)\n",
    "    variables_vif_sever = []\n",
    "    if 'vif_data' in locals():\n",
    "        vif_df = pd.DataFrame(vif_data)\n",
    "        variables_vif_sever = vif_df[vif_df['VIF'] > 10]['Variable'].tolist()\n",
    "        \n",
    "        print(f\"\\n ANÀLISI VIF:\")\n",
    "        for _, row in vif_df.iterrows():\n",
    "            var = row['Variable']\n",
    "            vif_val = row['VIF']\n",
    "            \n",
    "            if vif_val > 10:\n",
    "                status = \" SEVERA - ELIMINAR\"\n",
    "                accion = \" Eliminar del model\"\n",
    "            elif vif_val > 5:\n",
    "                status = \" MODERADA - MANTENIR\"\n",
    "                accion = \" Mantenir amb vigilància\"\n",
    "            elif vif_val > 2.5:\n",
    "                status = \" LLEUGERA - MANTENIR\"\n",
    "                accion = \" Mantenir\"\n",
    "            else:\n",
    "                status = \" OK - MANTENIR\"\n",
    "                accion = \" Mantenir\"\n",
    "                \n",
    "            print(f\"   {var}: VIF = {vif_val:.2f} - {status}\")\n",
    "            print(f\"      Acció: {accion}\")\n",
    "        \n",
    "        if variables_vif_sever:\n",
    "            print(f\"\\n  Variables amb multicol·linealitat severa (VIF > 10):\")\n",
    "            for var in variables_vif_sever:\n",
    "                vif_val = vif_df[vif_df['Variable'] == var]['VIF'].iloc[0]\n",
    "                r_squared = 1 - (1/vif_val)\n",
    "                print(f\"   - {var}: VIF = {vif_val:.2f} (R² = {r_squared:.3f})\")\n",
    "                print(f\"     Interpretació: Aquesta variable es pot explicar en un {r_squared*100:.1f}% per les altres variables\")\n",
    "            \n",
    "            # Model sense variables amb VIF sever\n",
    "            variables_sense_vif_sever = [v for v in variables_cox_finals \n",
    "                                        if v not in variables_vif_sever]\n",
    "            \n",
    "            print(f\"\\n MODEL SENSE MULTICOL·LINEALITAT SEVERA:\")\n",
    "            print(f\"Variables eliminades: {variables_vif_sever}\")\n",
    "            print(f\"Variables mantingudes: {variables_sense_vif_sever}\")\n",
    "            \n",
    "            if len(variables_sense_vif_sever) >= 2:\n",
    "                try:\n",
    "                    cph_sense_multicolineal = CoxPHFitter()\n",
    "                    df_sense_multicolineal = df_sense_estandarditzar[variables_sense_vif_sever + ['temps_mesos', 'event']].dropna()\n",
    "                    \n",
    "                    cph_sense_multicolineal.fit(df_sense_multicolineal, duration_col='temps_mesos', event_col='event')\n",
    "                    \n",
    "                    print(f\"\\n   RESULTATS MODEL:\")\n",
    "                    print(f\"   N pacients: {len(df_sense_multicolineal)}\")\n",
    "                    print(f\"   C-index: {cph_sense_multicolineal.concordance_index_:.3f}\")\n",
    "                    \n",
    "                    summary_corregit = cph_sense_multicolineal.summary\n",
    "                    for var, row in summary_corregit.iterrows():\n",
    "                        hr = np.exp(row['coef'])\n",
    "                        significatiu = \"***\" if row['p'] < 0.001 else \"**\" if row['p'] < 0.01 else \"*\" if row['p'] < 0.05 else \"\"\n",
    "                        print(f\"     {var}: HR={hr:.3f} p={row['p']:.4f} {significatiu}\")\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   Error: {str(e)}\")\n",
    "            else:\n",
    "                print(\"     Insuficients variables per crear model\")\n",
    "        else:\n",
    "            print(f\"\\n CAP VARIABLE AMB MULTICOL·LINEALITAT SEVERA\")\n",
    "            print(f\"   Totes les variables tenen VIF ≤ 10\")\n",
    "            print(f\"   El model original és acceptable des del punt de vista de multicol·linealitat\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PREPARACIÓ DE DADES PER A MODELATGE PREDICTIU\n",
    "# ============================================================================\n",
    "\n",
    "# Verificar que tenim el DataFrame net\n",
    "if 'df_clean' in locals():\n",
    "    df = df_clean\n",
    "else:\n",
    "    print(\" No es troba df_clean. Executa primer el codi de neteja.\")\n",
    "    exit()\n",
    "\n",
    "# Convertir a pandas per facilitar el modelatge\n",
    "df_pandas = df.to_pandas()\n",
    "\n",
    "# Anàlisi de mortalitat\n",
    "print(f\" Total pacients: {df_pandas['SIPCOD'].nunique():,}\")\n",
    "print(f\" Taxa de mortalitat: {df_pandas.groupby('SIPCOD')['fallecido'].first().mean():.1%}\")\n",
    "\n",
    "def crear_features_pacient_sense_imputacio(df):\n",
    "    \"\"\"Crea features agregades per pacient per a modelatge predictiu sense imputació\"\"\"\n",
    "    \n",
    "    # Agrupar per pacient\n",
    "    pacients_df = []\n",
    "    \n",
    "    for sipcod in df['SIPCOD'].unique():\n",
    "        dades_pacient = df[df['SIPCOD'] == sipcod].copy()\n",
    "        \n",
    "        # Variables demogràfiques\n",
    "        demo_cols = ['sexo', 'fecha Naci', 'fecha Exitus', 'fallecido', \n",
    "                     'TIPO_PACIENTE_FUSIONADO', 'HOSPITAL_FUSIONADO', 'ZONA_FUSIONADA']\n",
    "        features_pacient = dades_pacient[demo_cols].iloc[0].to_dict()\n",
    "        features_pacient['SIPCOD'] = sipcod\n",
    "        \n",
    "        # Edat \n",
    "        if not dades_pacient['edad_dias_medicion'].isna().all():\n",
    "            edat_primera = dades_pacient['edad_dias_medicion'].dropna().iloc[0]\n",
    "            features_pacient['edat_anys'] = edat_primera / 365.25\n",
    "        else:\n",
    "            features_pacient['edat_anys'] = np.nan\n",
    "        \n",
    "        # Features de variables numèriques \n",
    "        for variable in ['ALBUMINA', 'PCR', 'CREATININA', 'Rockwood']:\n",
    "            dades_var = dades_pacient[dades_pacient['Variable'] == variable]['valor_numerico'].dropna()\n",
    "            \n",
    "            if len(dades_var) > 0:\n",
    "                features_pacient[f'{variable}_primera'] = dades_var.iloc[0]\n",
    "                features_pacient[f'{variable}_mitjana'] = dades_var.mean()\n",
    "                features_pacient[f'{variable}_max'] = dades_var.max()\n",
    "                features_pacient[f'{variable}_min'] = dades_var.min()\n",
    "                features_pacient[f'{variable}_n_mesures'] = len(dades_var)\n",
    "                \n",
    "                if len(dades_var) > 1:\n",
    "                    features_pacient[f'{variable}_tendencia'] = (dades_var.iloc[-1] - dades_var.iloc[0]) / len(dades_var)\n",
    "                else:\n",
    "                    features_pacient[f'{variable}_tendencia'] = 0\n",
    "                    \n",
    "                # Flag de disponibilitat\n",
    "                features_pacient[f'{variable}_disponible'] = 1\n",
    "            else:\n",
    "                # No crear features per a variables sense dades\n",
    "                features_pacient[f'{variable}_disponible'] = 0\n",
    "        \n",
    "        # Features d'EuroQol\n",
    "        euroqol_vars = ['EQ5D_Movilidad', 'EQ5D_CuidadoPersonal', 'EQ5D_ActividadesHabituales',\n",
    "                       'EQ5D_DolorMalestar', 'EQ5D_AnsiedadDepresion']\n",
    "        \n",
    "        for eq_var in euroqol_vars:\n",
    "            dades_eq = dades_pacient[dades_pacient['Variable'] == eq_var]['valor_ordinal'].dropna()\n",
    "            if len(dades_eq) > 0:\n",
    "                features_pacient[f'{eq_var}_mitjana'] = dades_eq.mean()\n",
    "                features_pacient[f'{eq_var}_primera'] = dades_eq.iloc[0]\n",
    "                features_pacient[f'{eq_var}_disponible'] = 1\n",
    "            else:\n",
    "                features_pacient[f'{eq_var}_disponible'] = 0\n",
    "        \n",
    "        # Temps total de seguiment\n",
    "        dates = pd.to_datetime(dades_pacient['Fecha']).dropna()\n",
    "        if len(dates) > 1:\n",
    "            features_pacient['temps_seguiment_dies'] = (dates.max() - dates.min()).days\n",
    "        else:\n",
    "            features_pacient['temps_seguiment_dies'] = 0\n",
    "            \n",
    "        # Nombre total de mesures\n",
    "        features_pacient['total_mesures'] = len(dades_pacient)\n",
    "        \n",
    "        pacients_df.append(features_pacient)\n",
    "    \n",
    "    return pd.DataFrame(pacients_df)\n",
    "\n",
    "# Crear dataset de pacients\n",
    "features_pacients = crear_features_pacient_sense_imputacio(df_pandas)\n",
    "\n",
    "# Variable objectiu\n",
    "y = features_pacients['fallecido'].astype(int)\n",
    "\n",
    "# Variables bàsiques i anàlisi de completitud\n",
    "variables_cliniques = ['ALBUMINA', 'PCR', 'CREATININA', 'Rockwood']\n",
    "euroqol_vars = ['EQ5D_Movilidad', 'EQ5D_CuidadoPersonal', 'EQ5D_ActividadesHabituales',\n",
    "               'EQ5D_DolorMalestar', 'EQ5D_AnsiedadDepresion']\n",
    "\n",
    "variables_base = ['temps_seguiment_dies', 'total_mesures']\n",
    "\n",
    "# Variables categòriques \n",
    "features_categoriques = ['sexo', 'TIPO_PACIENTE_FUSIONADO', 'HOSPITAL_FUSIONADO', 'ZONA_FUSIONADA']\n",
    "\n",
    "# Flags de disponibilitat\n",
    "flags_disponibilitat = []\n",
    "for var in variables_cliniques + euroqol_vars:\n",
    "    flags_disponibilitat.append(f'{var}_disponible')\n",
    "\n",
    "X_base = features_pacients[variables_base + flags_disponibilitat].copy()\n",
    "\n",
    "# Afegir edat si està disponible \n",
    "X_base['edat_anys'] = features_pacients['edat_anys'].fillna(-1)\n",
    "X_base['edat_disponible'] = (features_pacients['edat_anys'].notna()).astype(int)\n",
    "\n",
    "# Processar variables categòriques\n",
    "X_categoriques = pd.DataFrame()\n",
    "label_encoders = {}\n",
    "\n",
    "for cat_col in features_categoriques:\n",
    "    if cat_col in features_pacients.columns:\n",
    "        le = LabelEncoder()\n",
    "        dades_cat = features_pacients[cat_col].fillna('Desconegut')\n",
    "        X_categoriques[cat_col] = le.fit_transform(dades_cat)\n",
    "        label_encoders[cat_col] = le\n",
    "\n",
    "# Variables amb millor completitud\n",
    "completitud = {}\n",
    "for var in variables_cliniques:\n",
    "    completitud[var] = features_pacients[f'{var}_disponible'].sum()\n",
    "\n",
    "vars_completes = sorted(completitud.keys(), key=lambda x: completitud[x], reverse=True)\n",
    "top_vars = vars_completes[:2]\n",
    "\n",
    "# ESTRATÈGIA MENYS RESTRICTIVA: només exigir variables bàsiques + edat\n",
    "mask_basic = features_pacients['edat_anys'].notna()\n",
    "pacients_basics = features_pacients[mask_basic].copy()\n",
    "\n",
    "# ESTRATÈGIA MODERADA: exigir almenys una variable clínica\n",
    "mask_moderat = mask_basic & (\n",
    "    (features_pacients['ALBUMINA_disponible'] == 1) |\n",
    "    (features_pacients['PCR_disponible'] == 1) |\n",
    "    (features_pacients['CREATININA_disponible'] == 1) |\n",
    "    (features_pacients['Rockwood_disponible'] == 1)\n",
    ")\n",
    "pacients_moderats = features_pacients[mask_moderat].copy()\n",
    "\n",
    "# Decidir quina estratègia utilitzar\n",
    "if len(pacients_moderats) >= 50:\n",
    "    pacients_complets = pacients_moderats.copy()\n",
    "    estrategia_usada = \"moderada\"\n",
    "    print(f\" Usant estratègia moderada: {len(pacients_complets)} pacients\")\n",
    "elif len(pacients_basics) >= 50:\n",
    "    pacients_complets = pacients_basics.copy()\n",
    "    estrategia_usada = \"bàsica\"\n",
    "    print(f\" Usant estratègia bàsica: {len(pacients_complets)} pacients\")\n",
    "else:\n",
    "    usar_casos_complets = False\n",
    "    estrategia_usada = \"només_flags\"\n",
    "    print(f\"  Pocs casos disponibles. Usant només flags.\")\n",
    "\n",
    "usar_casos_complets = estrategia_usada != \"només_flags\"\n",
    "\n",
    "if usar_casos_complets:\n",
    "    print(f\" Casos complets finals: {len(pacients_complets)}/{len(features_pacients)} ({len(pacients_complets)/len(features_pacients)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"  Pocs casos complets nets. Usant estratègia amb flags.\")\n",
    "\n",
    "# Dataset 1: Tots els casos amb flags de disponibilitat\n",
    "X_tots = pd.concat([X_base, X_categoriques], axis=1)\n",
    "\n",
    "# Dataset 2: Casos amb estratègia adaptativa\n",
    "if usar_casos_complets:\n",
    "    features_complets_cols = ['edat_anys', 'temps_seguiment_dies', 'total_mesures']\n",
    "    \n",
    "    # Afegir variables clíniques disponibles\n",
    "    for var in variables_cliniques:\n",
    "        if f'{var}_disponible' in pacients_complets.columns:\n",
    "            # Només afegir si almenys 20% dels pacients tenen aquesta variable\n",
    "            disponibilitat = pacients_complets[f'{var}_disponible'].mean()\n",
    "            if disponibilitat >= 0.2:\n",
    "                features_complets_cols.extend([\n",
    "                    f'{var}_primera', f'{var}_mitjana', f'{var}_max', \n",
    "                    f'{var}_min', f'{var}_n_mesures', f'{var}_tendencia'\n",
    "                ])\n",
    "    \n",
    "    # Variables EuroQol disponibles\n",
    "    for eq_var in euroqol_vars:\n",
    "        if f'{eq_var}_disponible' in pacients_complets.columns:\n",
    "            disponibilitat_eq = pacients_complets[f'{eq_var}_disponible'].mean()\n",
    "            if disponibilitat_eq >= 0.1:  # Criteri més relaxat per EuroQol\n",
    "                features_complets_cols.extend([f'{eq_var}_mitjana', f'{eq_var}_primera'])\n",
    "    \n",
    "    # Filtrar només les columnes que realment existeixen\n",
    "    features_existents = []\n",
    "    for col in features_complets_cols:\n",
    "        if col in pacients_complets.columns:\n",
    "            features_existents.append(col)\n",
    "    \n",
    "    print(f\" Variables seleccionades: {len(features_existents)}\")\n",
    "    print(f\" Variables: {features_existents}\")  # Mostrar primeres 10\n",
    "    \n",
    "    X_complets_num = pacients_complets[features_existents].copy()\n",
    "    \n",
    "    # Variables categòriques incloses\n",
    "    X_complets_cat = pd.DataFrame(index=pacients_complets.index)\n",
    "    for cat_col in features_categoriques:\n",
    "        if cat_col in pacients_complets.columns:\n",
    "            dades_cat = pacients_complets[cat_col].fillna('Desconegut')\n",
    "            X_complets_cat[cat_col] = label_encoders[cat_col].transform(dades_cat)\n",
    "    \n",
    "    X_complets = pd.concat([X_complets_num, X_complets_cat], axis=1)\n",
    "    \n",
    "    # Variable objectiu\n",
    "    y_complet = pacients_complets['fallecido'].astype(int)\n",
    "    \n",
    "    # Eliminar files amb massa NaN\n",
    "\n",
    "    # Contar NaN per fila\n",
    "    nan_per_fila = X_complets.isnull().sum(axis=1)\n",
    "    percentatge_nan = nan_per_fila / X_complets.shape[1]\n",
    "    \n",
    "    # Mantenir files amb menys del 50% de NaN\n",
    "    mask_acceptable = percentatge_nan < 0.5\n",
    "    \n",
    "    X_complets_net = X_complets[mask_acceptable].copy()\n",
    "    y_complet_net = y_complet[mask_acceptable].copy()\n",
    "    \n",
    "    # Per a les columnes restants amb NaN, omplir amb valors neutres\n",
    "    # Variables numèriques: usar -999 com a indicador \"sense dada\"\n",
    "    for col in X_complets_net.select_dtypes(include=[np.number]).columns:\n",
    "        X_complets_net[col] = X_complets_net[col].fillna(-999)\n",
    "    \n",
    "    # Actualitzar variables finals\n",
    "    X_complets = X_complets_net\n",
    "    y_complet = y_complet_net\n",
    "    \n",
    "    print(f\" Casos finals: {len(X_complets)}\")\n",
    "    print(f\" Variables finals: {X_complets.iloc[0]}\")\n",
    "    print(f\" NaN restants: {X_complets.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Verificar suficiència final\n",
    "    if len(X_complets) < 30:\n",
    "        print(\"  Molt pocs casos nets. Usant només estratègia amb flags.\")\n",
    "        usar_casos_complets = False\n",
    "\n",
    "# Divisió train/test i entrenament de models\n",
    "X_train_tots, X_test_tots, y_train_tots, y_test_tots = train_test_split(\n",
    "    X_tots, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Escalat\n",
    "scaler_tots = StandardScaler()\n",
    "X_train_tots_scaled = scaler_tots.fit_transform(X_train_tots)\n",
    "X_test_tots_scaled = scaler_tots.transform(X_test_tots)\n",
    "\n",
    "# Models\n",
    "models_tots = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=8, min_samples_split=10, \n",
    "        min_samples_leaf=5, random_state=42, class_weight='balanced'\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100, max_depth=4, learning_rate=0.1, \n",
    "        random_state=42\n",
    "    ),\n",
    "    'Regressió Logística': LogisticRegression(\n",
    "        random_state=42, class_weight='balanced', max_iter=1000\n",
    "    )\n",
    "}\n",
    "\n",
    "# Entrenar models\n",
    "resultats_tots = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for nom, model in models_tots.items():\n",
    "    if nom in ['Regressió Logística']:\n",
    "        model.fit(X_train_tots_scaled, y_train_tots)\n",
    "        y_pred_proba = model.predict_proba(X_test_tots_scaled)[:, 1]\n",
    "        cv_scores = cross_val_score(model, X_train_tots_scaled, y_train_tots, cv=cv, scoring='roc_auc')\n",
    "    else:\n",
    "        model.fit(X_train_tots, y_train_tots)\n",
    "        y_pred_proba = model.predict_proba(X_test_tots)[:, 1]\n",
    "        cv_scores = cross_val_score(model, X_train_tots, y_train_tots, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test_tots, y_pred_proba)\n",
    "    \n",
    "    resultats_tots[nom] = {\n",
    "        'model': model,\n",
    "        'auc_test': auc_score,\n",
    "        'auc_cv_mean': cv_scores.mean(),\n",
    "        'auc_cv_std': cv_scores.std(),\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"  {nom}: AUC {auc_score:.3f} (CV: {cv_scores.mean():.3f}±{cv_scores.std():.3f})\")\n",
    "\n",
    "# Modelatge amb casos complets \n",
    "resultats_complets = {}\n",
    "\n",
    "if usar_casos_complets:\n",
    "    X_train_comp, X_test_comp, y_train_comp, y_test_comp = train_test_split(\n",
    "        X_complets, y_complet, test_size=0.2, random_state=42, stratify=y_complet\n",
    "    )\n",
    "    \n",
    "    scaler_comp = StandardScaler()\n",
    "    X_train_comp_scaled = scaler_comp.fit_transform(X_train_comp)\n",
    "    X_test_comp_scaled = scaler_comp.transform(X_test_comp)\n",
    "    \n",
    "    for nom, _ in models_tots.items():\n",
    "        if nom == 'Random Forest':\n",
    "            model_comp = RandomForestClassifier(\n",
    "                n_estimators=100, max_depth=8, min_samples_split=5, \n",
    "                min_samples_leaf=2, random_state=42, class_weight='balanced'\n",
    "            )\n",
    "        elif nom == 'Gradient Boosting':\n",
    "            model_comp = GradientBoostingClassifier(\n",
    "                n_estimators=100, max_depth=4, learning_rate=0.1, \n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            model_comp = LogisticRegression(\n",
    "                random_state=42, class_weight='balanced', max_iter=1000\n",
    "            )\n",
    "        \n",
    "        if nom in ['Regressió Logística']:\n",
    "            model_comp.fit(X_train_comp_scaled, y_train_comp)\n",
    "            y_pred_proba_comp = model_comp.predict_proba(X_test_comp_scaled)[:, 1]\n",
    "            try:\n",
    "                cv_scores_comp = cross_val_score(model_comp, X_train_comp_scaled, y_train_comp, cv=cv, scoring='roc_auc')\n",
    "            except:\n",
    "                cv_scores_comp = np.array([np.nan])\n",
    "        else:\n",
    "            model_comp.fit(X_train_comp, y_train_comp)\n",
    "            y_pred_proba_comp = model_comp.predict_proba(X_test_comp)[:, 1]\n",
    "            try:\n",
    "                cv_scores_comp = cross_val_score(model_comp, X_train_comp, y_train_comp, cv=cv, scoring='roc_auc')\n",
    "            except:\n",
    "                cv_scores_comp = np.array([np.nan])\n",
    "        \n",
    "        auc_score_comp = roc_auc_score(y_test_comp, y_pred_proba_comp)\n",
    "        \n",
    "        resultats_complets[nom] = {\n",
    "            'model': model_comp,\n",
    "            'auc_test': auc_score_comp,\n",
    "            'auc_cv_mean': cv_scores_comp.mean(),\n",
    "            'auc_cv_std': cv_scores_comp.std(),\n",
    "            'y_pred_proba': y_pred_proba_comp\n",
    "        }\n",
    "        \n",
    "        print(f\"  {nom}: AUC {auc_score_comp:.3f} (CV: {cv_scores_comp.mean():.3f}±{cv_scores_comp.std():.3f})\")\n",
    "\n",
    "# Determinar millor model i estratègia\n",
    "millor_tots = max(resultats_tots.keys(), key=lambda x: resultats_tots[x]['auc_test'])\n",
    "\n",
    "if usar_casos_complets:\n",
    "    millor_complets = max(resultats_complets.keys(), key=lambda x: resultats_complets[x]['auc_test'])\n",
    "    \n",
    "    if resultats_complets[millor_complets]['auc_test'] > resultats_tots[millor_tots]['auc_test']:\n",
    "        print(f\"\\n MILLOR OPCIÓ: Casos complets ({millor_complets}) - AUC: {resultats_complets[millor_complets]['auc_test']:.3f}\")\n",
    "        millor_estrategia = 'complets'\n",
    "        millor_model_final = resultats_complets[millor_complets]['model']\n",
    "        millor_auc_final = resultats_complets[millor_complets]['auc_test']\n",
    "    else:\n",
    "        print(f\"\\n MILLOR OPCIÓ: Dataset complet amb flags ({millor_tots}) - AUC: {resultats_tots[millor_tots]['auc_test']:.3f}\")\n",
    "        millor_estrategia = 'tots'\n",
    "        millor_model_final = resultats_tots[millor_tots]['model']\n",
    "        millor_auc_final = resultats_tots[millor_tots]['auc_test']\n",
    "else:\n",
    "    print(f\"\\n MODEL FINAL: Dataset complet amb flags ({millor_tots}) - AUC: {resultats_tots[millor_tots]['auc_test']:.3f}\")\n",
    "    millor_estrategia = 'tots'\n",
    "    millor_model_final = resultats_tots[millor_tots]['model']\n",
    "    millor_auc_final = resultats_tots[millor_tots]['auc_test']\n",
    "\n",
    "# VISUALITZACIÓ DE RESULTATS\n",
    "# ============================================================================\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Subplot 1: Comparació de models dataset complet\n",
    "plt.subplot(2, 3, 1)\n",
    "\n",
    "colors = ['red', 'yellow', 'green']\n",
    "\n",
    "for i, (nom, resultat) in enumerate(resultats_tots.items()):\n",
    "    fpr, tpr, _ = roc_curve(y_test_tots, resultat['y_pred_proba'])\n",
    "    auc = resultat['auc_test']\n",
    "    color = colors[i % len(colors)]  \n",
    "    plt.plot(fpr, tpr, color=color, label=f'{nom} (AUC = {auc:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positius')\n",
    "plt.ylabel('Taxa de Veritables Positius')\n",
    "plt.title('ROC - Dataset Complet')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# Subplot 2: Comparació casos complets \n",
    "if usar_casos_complets:\n",
    "    plt.subplot(2, 3, 2)\n",
    "    for i, (nom, resultat) in enumerate(resultats_complets.items()):\n",
    "        fpr, tpr, _ = roc_curve(y_test_comp, resultat['y_pred_proba'])\n",
    "        auc = resultat['auc_test']\n",
    "        color = colors[i % len(colors)]\n",
    "        plt.plot(fpr, tpr, color=color, label=f'{nom} (AUC = {auc:.3f})', linewidth=2)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positius')\n",
    "    plt.ylabel('Taxa de Veritables Positius')\n",
    "    plt.title('ROC - Casos Complets')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 3: Completitud de dades\n",
    "plt.subplot(2, 3, 3)\n",
    "completitud_vars = []\n",
    "completitud_vals = []\n",
    "\n",
    "for var in variables_cliniques[:4]:\n",
    "    completitud_vars.append(var)\n",
    "    completitud_vals.append((features_pacients[f'{var}_disponible'].sum() / len(features_pacients)) * 100)\n",
    "\n",
    "plt.barh(completitud_vars, completitud_vals, color='lightblue')\n",
    "plt.xlabel('% Completitud')\n",
    "plt.title('Completitud de Variables Clíniques')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 4: Importància de variables\n",
    "plt.subplot(2, 3, 4)\n",
    "if hasattr(millor_model_final, 'feature_importances_'):\n",
    "    if millor_estrategia == 'tots':\n",
    "        importancies = millor_model_final.feature_importances_\n",
    "        noms_features = X_train_tots.columns\n",
    "    else:\n",
    "        importancies = millor_model_final.feature_importances_\n",
    "        noms_features = X_train_comp.columns\n",
    "    \n",
    "    df_importancia = pd.DataFrame({\n",
    "        'variable': noms_features,\n",
    "        'importancia': importancies\n",
    "    }).sort_values('importancia', ascending=False).head(20)\n",
    "    \n",
    "    plt.barh(range(len(df_importancia)), df_importancia['importancia'], color='red')\n",
    "    plt.yticks(range(len(df_importancia)), df_importancia['variable'])\n",
    "    plt.xlabel('Importància')\n",
    "    plt.title(f'Top Variables - {millor_tots if millor_estrategia == \"tots\" else millor_complets}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 5: Distribució de probabilitats predites\n",
    "plt.subplot(2, 3, 5)\n",
    "if millor_estrategia == 'tots':\n",
    "    y_pred_millor = resultats_tots[millor_tots]['y_pred_proba']\n",
    "    y_test_millor = y_test_tots\n",
    "else:\n",
    "    y_pred_millor = resultats_complets[millor_complets]['y_pred_proba']\n",
    "    y_test_millor = y_test_comp\n",
    "\n",
    "plt.hist(y_pred_millor[y_test_millor == 0], bins=20, alpha=0.7, label='Supervivents', color='blue')\n",
    "plt.hist(y_pred_millor[y_test_millor == 1], bins=20, alpha=0.7, label='Difunts', color='red')\n",
    "plt.xlabel('Probabilitat Predita')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title('Distribució de Probabilitats')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 6: Matriu de confusió\n",
    "plt.subplot(2, 3, 6)\n",
    "fpr_millor, tpr_millor, thresholds = roc_curve(y_test_millor, y_pred_millor)\n",
    "optimal_idx = np.argmax(tpr_millor - fpr_millor)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "y_pred_binary = (y_pred_millor >= optimal_threshold).astype(int)\n",
    "cm = confusion_matrix(y_test_millor, y_pred_binary)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', \n",
    "            xticklabels=['Supervivents', 'Difunts'],\n",
    "            yticklabels=['Supervivents', 'Difunts'])\n",
    "plt.title(f'Matriu de Confusió\\n(Llindar = {optimal_threshold:.3f})')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Predicció')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Descompondre la matriu\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "# Mètriques de validació\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "sensitivity = TP / (TP + FN)  # Recall o True Positive Rate\n",
    "specificity = TN / (TN + FP)  # True Negative Rate\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "f1 = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) != 0 else 0\n",
    "\n",
    "# Mostrar els resultats\n",
    "print(f\"Accuracy:     {accuracy:.3f}\")\n",
    "print(f\"Sensibilitat: {sensitivity:.3f}\")\n",
    "print(f\"Especificitat:{specificity:.3f}\")\n",
    "print(f\"Precisión:    {precision:.3f}\")\n",
    "print(f\"F1-Score:     {f1:.3f}\")\n",
    "\n",
    "# CONCLUSIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n CONCLUSIONS :\")\n",
    "print(\"=\"*50)\n",
    "print(f\" Millor estratègia: {'Casos complets' if millor_estrategia == 'complets' else 'Dataset amb flags'}\")\n",
    "print(f\" Millor model: {millor_complets if millor_estrategia == 'complets' else millor_tots}\")\n",
    "print(f\" AUC final: {millor_auc_final:.3f}\")\n",
    "print(f\" Total pacients: {len(features_pacients):,}\")\n",
    "print(f\" Taxa mortalitat: {features_pacients['fallecido'].mean():.1%}\")\n",
    "\n",
    "if hasattr(millor_model_final, 'feature_importances_'):\n",
    "    print(f\"\\n TOP 5 VARIABLES MÉS IMPORTANTS:\")\n",
    "    if millor_estrategia == 'tots':\n",
    "        noms_features = X_train_tots.columns\n",
    "    else:\n",
    "        noms_features = X_train_comp.columns\n",
    "    \n",
    "    df_importancia = pd.DataFrame({\n",
    "        'variable': noms_features,\n",
    "        'importancia': millor_model_final.feature_importances_\n",
    "    }).sort_values('importancia', ascending=False)\n",
    "    \n",
    "    for i, row in df_importancia.head(5).iterrows():\n",
    "        print(f\"  {row['variable']}: {row['importancia']:.4f}\")\n",
    "\n",
    "# CROSS-VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, learning_curve\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def cross_validation_complet(models_dict, X, y, cv_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Realitza cross-validation complet amb múltiples mètriques\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definir mètriques d'avaluació\n",
    "    scoring = {\n",
    "        'roc_auc': 'roc_auc',\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "    \n",
    "    # Configurar cross-validation\n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    resultats_cv = {}\n",
    "    \n",
    "    for nom_model, model in models_dict.items():\n",
    "        print(f\"\\n Avaluant {nom_model}...\")\n",
    "        \n",
    "        # Executar cross-validation\n",
    "        cv_results = cross_validate(\n",
    "            model, X, y, \n",
    "            cv=cv, \n",
    "            scoring=scoring,\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Calcular estadístiques\n",
    "        resultats_model = {}\n",
    "        for metric in scoring.keys():\n",
    "            test_scores = cv_results[f'test_{metric}']\n",
    "            train_scores = cv_results[f'train_{metric}']\n",
    "            \n",
    "            resultats_model[f'{metric}_test_mean'] = np.mean(test_scores)\n",
    "            resultats_model[f'{metric}_test_std'] = np.std(test_scores)\n",
    "            resultats_model[f'{metric}_train_mean'] = np.mean(train_scores)\n",
    "            resultats_model[f'{metric}_train_std'] = np.std(train_scores)\n",
    "            resultats_model[f'{metric}_test_scores'] = test_scores\n",
    "            resultats_model[f'{metric}_train_scores'] = train_scores\n",
    "            \n",
    "            # Calcular overfitting \n",
    "            overfitting = np.mean(train_scores) - np.mean(test_scores)\n",
    "            resultats_model[f'{metric}_overfitting'] = overfitting\n",
    "        \n",
    "        resultats_cv[nom_model] = resultats_model\n",
    "        \n",
    "        # Mostrar resultats\n",
    "        print(f\"  AUC Test:  {resultats_model['roc_auc_test_mean']:.3f} ± {resultats_model['roc_auc_test_std']:.3f}\")\n",
    "        print(f\"  AUC Train: {resultats_model['roc_auc_train_mean']:.3f} ± {resultats_model['roc_auc_train_std']:.3f}\")\n",
    "        print(f\"  Overfitting: {resultats_model['roc_auc_overfitting']:.3f}\")\n",
    "        print(f\"  Accuracy:  {resultats_model['accuracy_test_mean']:.3f} ± {resultats_model['accuracy_test_std']:.3f}\")\n",
    "        print(f\"  F1-Score:  {resultats_model['f1_test_mean']:.3f} ± {resultats_model['f1_test_std']:.3f}\")\n",
    "    \n",
    "    return resultats_cv\n",
    "\n",
    "def visualitzar_cv_results(resultats_cv):\n",
    "    \"\"\"\n",
    "    Crea visualitzacions dels resultats de cross-validation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparar dades per visualització\n",
    "    models = list(resultats_cv.keys())\n",
    "    metriques = ['roc_auc', 'accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Resultats Cross-Validation', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Comparació mètriques principals\n",
    "    ax1 = axes[0, 0]\n",
    "    x_pos = np.arange(len(models))\n",
    "    width = 0.15\n",
    "    \n",
    "    colors=['pink', 'orange', 'purple']\n",
    "\n",
    "    for i, metric in enumerate(['roc_auc', 'accuracy', 'f1']):\n",
    "        means = [resultats_cv[model][f'{metric}_test_mean'] for model in models]\n",
    "        stds = [resultats_cv[model][f'{metric}_test_std'] for model in models]\n",
    "        \n",
    "        ax1.bar(x_pos + i*width, means, width, \n",
    "               yerr=stds, capsize=3, \n",
    "               label=metric.replace('_', ' ').title(), color = colors[i % len(colors)],\n",
    "               alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Models')\n",
    "    ax1.set_ylabel('Puntuació')\n",
    "    ax1.set_title('Comparació Mètriques Principals')\n",
    "    ax1.set_xticks(x_pos + width)\n",
    "    ax1.set_xticklabels(models, rotation=45)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Boxplot AUC per model\n",
    "    ax2 = axes[0, 1]\n",
    "    auc_data = []\n",
    "    labels_auc = []\n",
    "    \n",
    "    for model in models:\n",
    "        auc_scores = resultats_cv[model]['roc_auc_test_scores']\n",
    "        auc_data.append(auc_scores)\n",
    "        labels_auc.append(model)\n",
    "    \n",
    "    box_plot = ax2.boxplot(auc_data, labels=labels_auc, patch_artist=True)\n",
    "    colors = ['red', 'yellow', 'green']\n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax2.set_title('Distribució AUC Cross-Validation')\n",
    "    ax2.set_ylabel('AUC Score')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # 3. Overfitting comparison\n",
    "    ax3 = axes[0, 2]\n",
    "    overfitting_auc = [resultats_cv[model]['roc_auc_overfitting'] for model in models]\n",
    "    overfitting_acc = [resultats_cv[model]['accuracy_overfitting'] for model in models]\n",
    "    \n",
    "    x_pos = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax3.bar(x_pos - width/2, overfitting_auc, width, label='AUC', alpha=0.8, color='red')\n",
    "    ax3.bar(x_pos + width/2, overfitting_acc, width, label='Accuracy', alpha=0.8, color='blue')\n",
    "    \n",
    "    ax3.set_xlabel('Models')\n",
    "    ax3.set_ylabel('Overfitting (Train - Test)')\n",
    "    ax3.set_title('Nivell d\\'Overfitting per Model')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(models, rotation=45)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 4. Matriu de correlació entre mètriques\n",
    "    ax4 = axes[1, 0]\n",
    "    \n",
    "    # Crear dataframe amb totes les mètriques\n",
    "    df_metriques = pd.DataFrame()\n",
    "    for model in models:\n",
    "        for metric in metriques:\n",
    "            scores = resultats_cv[model][f'{metric}_test_scores']\n",
    "            for i, score in enumerate(scores):\n",
    "                df_metriques = pd.concat([df_metriques, pd.DataFrame({\n",
    "                    'Model': [model],\n",
    "                    'Fold': [i],\n",
    "                    'AUC': [resultats_cv[model]['roc_auc_test_scores'][i]],\n",
    "                    'Accuracy': [resultats_cv[model]['accuracy_test_scores'][i]],\n",
    "                    'Precision': [resultats_cv[model]['precision_test_scores'][i]],\n",
    "                    'Recall': [resultats_cv[model]['recall_test_scores'][i]],\n",
    "                    'F1': [resultats_cv[model]['f1_test_scores'][i]]\n",
    "                })], ignore_index=True)\n",
    "    \n",
    "    corr_matrix = df_metriques[['AUC', 'Accuracy', 'Precision', 'Recall', 'F1']].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, ax=ax4)\n",
    "    ax4.set_title('Correlació entre Mètriques')\n",
    "    \n",
    "    # 5. Estabilitat dels models\n",
    "    ax5 = axes[1, 1]\n",
    "    \n",
    "    variabilitat = {}\n",
    "    for model in models:\n",
    "        variabilitat[model] = resultats_cv[model]['roc_auc_test_std']\n",
    "    \n",
    "    models_sorted = sorted(variabilitat.keys(), key=lambda x: variabilitat[x])\n",
    "    vals = [variabilitat[model] for model in models_sorted]\n",
    "    \n",
    "    bars = ax5.bar(models_sorted, vals, color=['red', 'green', 'yellow'], alpha=0.7)\n",
    "    ax5.set_xlabel('Models')\n",
    "    ax5.set_ylabel('Desviació Estàndard AUC')\n",
    "    ax5.set_title('Estabilitat dels Models')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    plt.setp(ax5.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # Afegir valors a les barres\n",
    "    for bar, val in zip(bars, vals):\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 6. Rendiment per fold\n",
    "    ax6 = axes[1, 2]\n",
    "    \n",
    "    colors = ['red', 'yellow', 'green']  \n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        folds = range(1, len(resultats_cv[model]['roc_auc_test_scores']) + 1)\n",
    "        auc_scores = resultats_cv[model]['roc_auc_test_scores']\n",
    "        ax6.plot(folds, auc_scores, marker='o', color=colors[i], label=model, linewidth=2)\n",
    "    \n",
    "    ax6.set_xlabel('Fold')\n",
    "    ax6.set_ylabel('AUC Score')\n",
    "    ax6.set_title('Rendiment per Fold')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    ax6.set_xticks(range(1, 6))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def crear_taula_resum_cv(resultats_cv):\n",
    "    \"\"\"\n",
    "    Crea una taula resum dels resultats de cross-validation\n",
    "    \"\"\"\n",
    "    \n",
    "    resum_data = []\n",
    "    \n",
    "    for model in resultats_cv.keys():\n",
    "        fila = {\n",
    "            'Model': model,\n",
    "            'AUC_Mean': f\"{resultats_cv[model]['roc_auc_test_mean']:.3f}\",\n",
    "            'AUC_Std': f\"{resultats_cv[model]['roc_auc_test_std']:.3f}\",\n",
    "            'Accuracy_Mean': f\"{resultats_cv[model]['accuracy_test_mean']:.3f}\",\n",
    "            'Accuracy_Std': f\"{resultats_cv[model]['accuracy_test_std']:.3f}\",\n",
    "            'F1_Mean': f\"{resultats_cv[model]['f1_test_mean']:.3f}\",\n",
    "            'F1_Std': f\"{resultats_cv[model]['f1_test_std']:.3f}\",\n",
    "            'Overfitting_AUC': f\"{resultats_cv[model]['roc_auc_overfitting']:.3f}\",\n",
    "            'Estabilitat': 'Alta' if resultats_cv[model]['roc_auc_test_std'] < 0.05 else 'Baixa'\n",
    "        }\n",
    "        resum_data.append(fila)\n",
    "    \n",
    "    df_resum = pd.DataFrame(resum_data)\n",
    "    \n",
    "    print(\"\\n TAULA RESUM CROSS-VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_resum.to_string(index=False))\n",
    "    \n",
    "    return df_resum\n",
    "\n",
    "# Per dataset amb flags\n",
    "resultats_cv_tots = cross_validation_complet(models_tots, X_train_tots, y_train_tots)\n",
    "\n",
    "# Per casos complets \n",
    "if usar_casos_complets:\n",
    "    resultats_cv_complets = cross_validation_complet(models_tots, X_train_comp, y_train_comp)\n",
    "    \n",
    "    print(f\"\\n COMPARACIÓ ESTRATÈGIES:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for model in models_tots.keys():\n",
    "        auc_tots = resultats_cv_tots[model]['roc_auc_test_mean']\n",
    "        auc_comp = resultats_cv_complets[model]['roc_auc_test_mean']\n",
    "        \n",
    "        print(f\"{model}:\")\n",
    "        print(f\"  Dataset complet: {auc_tots:.3f}\")\n",
    "        print(f\"  Casos complets:  {auc_comp:.3f}\")\n",
    "        print(f\"  Diferència:      {auc_comp - auc_tots:+.3f}\")\n",
    "\n",
    "# Crear visualitzacions\n",
    "visualitzar_cv_results(resultats_cv_tots)\n",
    "\n",
    "if usar_casos_complets:\n",
    "    visualitzar_cv_results(resultats_cv_complets)\n",
    "\n",
    "# Crear taules \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET COMPLET AMB FLAGS:\")\n",
    "taula_tots = crear_taula_resum_cv(resultats_cv_tots)\n",
    "\n",
    "if usar_casos_complets:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CASOS COMPLETS:\")\n",
    "    taula_complets = crear_taula_resum_cv(resultats_cv_complets)\n",
    "\n",
    "# Determinar millor model amb cross-validation\n",
    "millor_model_cv = max(resultats_cv_tots.keys(), \n",
    "                     key=lambda x: resultats_cv_tots[x]['roc_auc_test_mean'])\n",
    "\n",
    "print(f\"\\n MILLOR MODEL SEGONS CROSS-VALIDATION:\")\n",
    "print(f\"  Model: {millor_model_cv}\")\n",
    "print(f\"  AUC CV: {resultats_cv_tots[millor_model_cv]['roc_auc_test_mean']:.3f} ± {resultats_cv_tots[millor_model_cv]['roc_auc_test_std']:.3f}\")\n",
    "print(f\"  Overfitting: {resultats_cv_tots[millor_model_cv]['roc_auc_overfitting']:.3f}\")\n",
    "print(f\"  Estabilitat: {'Alta' if resultats_cv_tots[millor_model_cv]['roc_auc_test_std'] < 0.05 else 'Baixa'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
